(globalThis.TURBOPACK||(globalThis.TURBOPACK=[])).push(["object"==typeof document?document.currentScript:void 0,17394,e=>{"use strict";e.s(["ALL_YEARS",0,[2023,2024,2025,2026],"PHASES",0,["Strategy","Design","Spec","Dev","QA","DevOps"],"PHASE_WEIGHTS",0,{Strategy:.08,Design:.12,Spec:.1,Dev:.4,QA:.2,DevOps:.1},"facts",0,[{id:"str-1",phase:"Strategy",impactPct:15,year:2023,publishDate:"2023-09-15",source:"McKinsey — AI Transforming Strategy",sourceUrl:"https://www.mckinsey.com/capabilities/strategy-and-corporate-finance/our-insights/how-ai-is-transforming-strategy-development",dataType:"survey",description:"McKinsey analysis: AI transforms strategy development through faster scenario analysis and market intelligence synthesis, compressing strategic planning timelines for early adopters.",credibility:2},{id:"str-2",phase:"Strategy",impactPct:22,year:2024,publishDate:"2024-10-21",source:"Gartner — Top 10 Strategic Tech Trends 2025",sourceUrl:"https://www.gartner.com/en/newsroom/press-releases/2024-10-21-gartner-identifies-the-top-10-strategic-technology-trends-for-2025",dataType:"survey",description:"Gartner identifies agentic AI, AI governance platforms, and decision intelligence as top strategic trends for 2025, reshaping enterprise strategy formation and planning processes.",credibility:3},{id:"str-3",phase:"Strategy",impactPct:18,year:2024,publishDate:"2024-09-01",source:"HBR — AI Can Outperform Human CEOs",sourceUrl:"https://hbr.org/2024/09/ai-can-mostly-outperform-human-ceos",dataType:"empirical",description:"HBR study: GPT-4o tested in CEO-level business simulation outperformed human executives on most strategic decision tasks, demonstrating significant AI potential for strategy augmentation.",credibility:2},{id:"str-4",phase:"Strategy",impactPct:30,year:2025,publishDate:"2024-10-28",source:"Forrester — AI Predictions 2025",sourceUrl:"https://www.forrester.com/blogs/predictions-2025-artificial-intelligence/",dataType:"survey",description:"Forrester 2025 AI predictions: only 13% report positive EBITDA from AI so far. AI-augmented planning requires fundamental process redesign, not just tool deployment.",credibility:2},{id:"str-5",phase:"Strategy",impactPct:12,year:2025,publishDate:"2024-11-01",source:"Riverbed — Global AI Readiness Survey",sourceUrl:"https://www.riverbed.com/press-releases/global-survey-reveals-ai-readiness/",dataType:"survey",description:"Global survey: only 12% of AI projects have reached full enterprise-wide deployment, despite increasing investment. Highlights the gap between AI ambition and execution at scale.",credibility:2},{id:"str-6",phase:"Strategy",impactPct:35,year:2025,publishDate:"2025-01-15",source:"Gartner — AI Investment Framework",sourceUrl:"https://www.gartner.com/en/articles/ai-investments",dataType:"survey",description:"Gartner warns against narrow ROI framing for AI investments. Strategic, operational, and risk-reduction value often exceeds direct productivity gains. Recommends 2-3 year AI ROI timelines.",credibility:3},{id:"des-1",phase:"Design",impactPct:20,year:2023,publishDate:"2023-08-14",source:"Nielsen Norman Group — AI in UX Research",sourceUrl:"https://www.nngroup.com/articles/research-with-ai/",dataType:"anecdotal",description:"NNGroup reports AI tools accelerate UX research workflows, particularly in analysis and synthesis phases. AI-assisted methods compress usability study timelines significantly.",credibility:2},{id:"des-2",phase:"Design",impactPct:25,year:2024,publishDate:"2024-06-01",source:"Figma — AI Design Trends 2024",sourceUrl:"https://www.figma.com/reports/ai-design-trends-2024/",dataType:"survey",description:"Figma 2024 report: 59% of designers use AI tools, 22% use AI for first drafts of interfaces. AI adoption reshaping design workflows with measurable prototyping speed gains.",sampleSize:"1,800+ designers",credibility:2},{id:"des-3",phase:"Design",impactPct:15,year:2024,publishDate:"2024-05-15",source:"ACM CHI 2024 — GenAI and Design Fixation",sourceUrl:"https://dl.acm.org/doi/full/10.1145/3613904.3642919",dataType:"empirical",description:"CHI 2024 study: Generative AI and design fixation — AI tools generate more options but may reduce divergent thinking. Quality improvements depend on designer expertise and critical review.",sampleSize:"60 participants",credibility:3},{id:"des-4",phase:"Design",impactPct:28,year:2024,publishDate:"2024-06-01",source:"State of AI in Design Report",sourceUrl:"https://www.stateofaidesign.com/",dataType:"survey",description:"Annual survey tracking AI tool adoption among product designers. AI design tools showing significant gains in prototyping speed and iteration, reducing revision cycles.",credibility:2},{id:"des-5",phase:"Design",impactPct:35,year:2025,publishDate:"2025-03-15",source:"Adobe Design — AI-Powered Prototyping",sourceUrl:"https://adobe.design/stories/leading-design/from-idea-to-interface-a-designer-s-guide-to-ai-powered-prototyping",dataType:"anecdotal",description:"Adobe guide on AI-powered prototyping: generative design tools compress concept-to-prototype cycles from weeks to days through automated layout and component generation.",credibility:1},{id:"des-6",phase:"Design",impactPct:40,year:2025,publishDate:"2025-01-15",source:"Supernova — State of AI in Design Systems 2024",sourceUrl:"https://www.supernova.io/survey/state-of-ai-in-ds-2024-report",dataType:"survey",description:"Survey: AI-integrated design systems enable faster component creation and reduced design debt through automated documentation, token management, and code generation.",credibility:2},{id:"des-7",phase:"Design",impactPct:45,year:2025,publishDate:"2025-06-01",source:"Advances in HCI — AI in UX Evaluation",sourceUrl:"https://onlinelibrary.wiley.com/doi/10.1155/ahci/7442179",dataType:"empirical",description:"Systematic review of AI in automated and remote UX evaluation: AI methods identify a significant proportion of usability issues previously requiring human evaluators.",credibility:3},{id:"des-8",phase:"Design",impactPct:50,year:2026,publishDate:"2026-02-13",source:"Figma — State of the Designer 2026",sourceUrl:"https://www.figma.com/reports/state-of-the-designer-2026/",dataType:"survey",description:"Figma 2026 survey tracks AI feature adoption impact on design workflows, showing deepening integration of AI-powered auto-layout, generation, and prototyping tools.",sampleSize:"906 designers",credibility:2},{id:"spc-1",phase:"Spec",impactPct:25,year:2023,publishDate:"2023-12-01",source:"IEEE Software — RE and LLMs Panel",sourceUrl:"https://dl.acm.org/doi/10.1109/MS.2023.3339934",dataType:"empirical",description:"IEEE Software panel: experts discuss LLM potential to reduce ambiguity in specifications, with early evidence of improved consistency in AI-generated requirements documents.",credibility:2},{id:"spc-2",phase:"Spec",impactPct:30,year:2024,publishDate:"2024-10-01",source:"Atlassian — AI in Jira",sourceUrl:"https://www.atlassian.com/blog/artificial-intelligence/ai-jira-issues",dataType:"vendor",description:"Atlassian AI features for Jira auto-populate summaries, descriptions, and acceptance criteria from context, streamlining ticket creation and improving specification consistency.",credibility:1},{id:"spc-3",phase:"Spec",impactPct:20,year:2024,publishDate:"2024-03-15",source:"Product School — AI for PMs 2024",sourceUrl:"https://productschool.com/blog/artificial-intelligence/ai-for-product-managers-unlocking-growth-in-2024",dataType:"anecdotal",description:"Industry analysis: growing AI adoption among product managers for drafting PRDs and user stories. AI becoming standard in the PM toolkit for initial requirement generation.",credibility:1},{id:"spc-4",phase:"Spec",impactPct:13,year:2024,publishDate:"2024-06-24",source:"Requirements Conflicts Detection with AI (ResearchGate)",sourceUrl:"https://www.researchgate.net/publication/383290205_Requirements_Conflicts_Detection_Advancing_with_Conversational_AI",dataType:"empirical",description:"Research: hybrid LLM pipelines outperformed state-of-the-art requirements conflict detection by 13% F1-score, demonstrating AI potential for specification validation.",credibility:3},{id:"spc-5",phase:"Spec",impactPct:20,year:2024,publishDate:"2024-06-15",source:"ThoughtWorks Tech Radar — Spec-Driven Development",sourceUrl:"https://www.thoughtworks.com/radar/techniques/spec-driven-development",dataType:"anecdotal",description:"ThoughtWorks Technology Radar places spec-driven development in Assess ring, noting growing viability of AI-powered API specification generators for accelerating documentation.",credibility:2},{id:"spc-6",phase:"Spec",impactPct:42,year:2025,publishDate:"2025-07-01",source:"Anthropic — How Teams Use Claude Code",sourceUrl:"https://www.anthropic.com/news/how-anthropic-teams-use-claude-code",dataType:"vendor",description:"Anthropic internal study: 42% of engineers use Claude daily for code understanding, 55% for debugging. Self-reported ~50% productivity boost from AI integration in development workflows.",sampleSize:"132 engineers, 53 interviews",credibility:2},{id:"spc-7",phase:"Spec",impactPct:35,year:2025,publishDate:"2026-01-19",source:"Addy Osmani — Specs for AI Agents",sourceUrl:"https://addyosmani.com/blog/good-spec/",dataType:"anecdotal",description:"Google Chrome engineer documents best practices for AI-driven spec writing. Well-structured specifications enable AI agents to achieve high accuracy in code generation tasks.",credibility:1},{id:"dev-1",phase:"Dev",impactPct:26,year:2023,publishDate:"2022-09-07",source:"GitHub — Copilot Productivity & Happiness",sourceUrl:"https://github.blog/news-insights/research/research-quantifying-github-copilots-impact-on-developer-productivity-and-happiness/",dataType:"empirical",description:"GitHub research: Copilot users completed tasks 55% faster in controlled study. 60-75% report increased fulfillment. 87% preserve mental effort during repetitive tasks.",sampleSize:"95 developers",credibility:3},{id:"dev-2",phase:"Dev",impactPct:8,year:2024,publishDate:"2024-05-01",source:"Google — ML-Assisted Code Review (ICSE 2024)",sourceUrl:"https://research.google/pubs/resolving-code-review-comments-with-machine-learning/",dataType:"empirical",description:"Google ICSE 2024: ML-based tool automatically addresses ~7.5% of reviewer comments, demonstrating scalable AI potential for code review acceleration at large scale.",sampleSize:"Google-scale deployment",credibility:3},{id:"dev-3",phase:"Dev",impactPct:20,year:2024,publishDate:"2024-06-20",source:"Stack Overflow Developer Survey 2024",sourceUrl:"https://survey.stackoverflow.co/2024/ai",dataType:"survey",description:"Stack Overflow 2024: 76% of developers using or planning to use AI tools (up from 70%). 81% cite increased productivity as primary benefit. 62% currently using AI tools.",sampleSize:"65,000+ developers",credibility:3},{id:"dev-4",phase:"Dev",impactPct:30,year:2024,publishDate:"2024-06-15",source:"Microsoft Research — IntelliCode Completions",sourceUrl:"https://www.microsoft.com/en-us/research/project/intellicode-completions/",dataType:"empirical",description:"Microsoft IntelliCode uses deep learning for whole-line code completions, keeping developers in flow by predicting likely code patterns based on repository context.",credibility:2},{id:"dev-5",phase:"Dev",impactPct:30,year:2024,publishDate:"2024-06-01",source:"JetBrains — State of Developer Ecosystem 2024",sourceUrl:"https://www.jetbrains.com/lp/devecosystem-2024/",dataType:"survey",description:"JetBrains 2024: 56% regularly use ChatGPT for development, 73% have tried AI coding. Nearly 80% of companies allow third-party AI tools. AI adoption accelerating across ecosystems.",sampleSize:"23,262 developers",credibility:3},{id:"dev-6",phase:"Dev",impactPct:25,year:2024,publishDate:"2024-06-15",source:"McKinsey — Developer Productivity with GenAI",sourceUrl:"https://www.mckinsey.com/capabilities/tech-and-ai/our-insights/unleashing-developer-productivity-with-generative-ai",dataType:"empirical",description:"McKinsey benchmarks: AI assistants achieve 20-30% faster code refactoring, with high-complexity tasks showing less than 10% improvement. Gains concentrated in routine tasks.",sampleSize:"40 developer tasks",credibility:2},{id:"dev-7",phase:"Dev",impactPct:38,year:2024,publishDate:"2024-06-15",source:"Sourcegraph — Cody AI Assistant",sourceUrl:"https://sourcegraph.com/blog/cody-better-faster-stronger",dataType:"vendor",description:"Sourcegraph reports Cody users write code faster and save hours weekly through AI-powered code navigation, search, and contextual generation across large enterprise codebases.",credibility:1},{id:"dev-8",phase:"Dev",impactPct:50,year:2025,publishDate:"2025-05-20",source:"Anthropic — AI Transforming Work at Anthropic",sourceUrl:"https://www.anthropic.com/research/how-ai-is-transforming-work-at-anthropic",dataType:"vendor",description:"Anthropic internal: 55% use Claude daily for debugging, 42% for code understanding. Employees self-report ~50% productivity boost from AI across development workflows.",sampleSize:"132 engineers surveyed",credibility:2},{id:"dev-9",phase:"Dev",impactPct:55,year:2025,publishDate:"2025-06-15",source:"Cursor — AI-Native IDE",sourceUrl:"https://www.cursor.com",dataType:"vendor",description:"Cursor AI-native IDE: agent mode builds features across multiple files. Anecdotal reports of 3-4 hour tasks completed in 25 minutes. 250 tokens/second AI completion speed.",credibility:1},{id:"dev-10",phase:"Dev",impactPct:22,year:2025,publishDate:"2025-06-15",source:"ACM — AI Pair Programming Impact",sourceUrl:"https://dl.acm.org/doi/fullHtml/10.1145/3665348.3665383",dataType:"empirical",description:"ACM study on AI pair programming quality trade-offs: AI-assisted development improves task completion rates but may impact code readability and long-term maintainability.",credibility:3},{id:"dev-11",phase:"Dev",impactPct:14,year:2025,publishDate:"2024-03-15",source:"Cognition Labs — Devin SWE-bench Report",sourceUrl:"https://cognition.ai/blog/swe-bench-technical-report",dataType:"vendor",description:"Devin achieved 13.86% resolution rate (79/570) on SWE-bench — the first AI to autonomously resolve real-world GitHub issues, establishing baseline for agentic coding systems.",credibility:2},{id:"dev-12",phase:"Dev",impactPct:29,year:2023,publishDate:"2021-07-14",source:"OpenAI — Codex / HumanEval (arXiv)",sourceUrl:"https://arxiv.org/abs/2107.03374",dataType:"empirical",description:"OpenAI Codex achieved 28.8% pass@1 on HumanEval benchmark, establishing the foundation for code generation tools. Later models (GPT-3.5+) exceeded 67-85%.",credibility:3},{id:"dev-13",phase:"Dev",impactPct:55,year:2024,publishDate:"2024-10-29",source:"GitHub Octoverse 2024",sourceUrl:"https://github.blog/news-insights/octoverse/octoverse-2024/",dataType:"survey",description:"GitHub Octoverse 2024: AI is the #1 emerging tool in developer workflows. Developers using AI report shipping code faster and spending more time on creative problem-solving.",credibility:2},{id:"dev-14",phase:"Dev",impactPct:49,year:2025,publishDate:"2025-06-15",source:"SWE-bench — AI Coding Benchmark",sourceUrl:"https://www.swebench.com/",dataType:"empirical",description:"SWE-bench verified: frontier AI systems resolve 40-50%+ of real-world software engineering tasks by 2025-2026, demonstrating rapid improvement in autonomous code generation.",credibility:3},{id:"qa-1",phase:"QA",impactPct:28,year:2024,publishDate:"2024-03-15",source:"PractiTest — State of Testing 2024",sourceUrl:"https://www.practitest.com/resource-center/blog/unveiling-the-2024-state-of-testing/",dataType:"survey",description:"28% of testers report measurable productivity gains from AI testing tools. 50% expect GenAI to improve test automation efficiency. AI adoption growing but still maturing.",credibility:2},{id:"qa-2",phase:"QA",impactPct:25,year:2024,publishDate:"2025-04-07",source:"arXiv — AI Adoption in Testing (Secondary Study)",sourceUrl:"https://arxiv.org/html/2504.04921v1",dataType:"empirical",description:"Systematic secondary study of AI adoption in testing: expectations vs reality. Actual productivity gains more modest than vendor claims, averaging 20-30% for test creation tasks.",credibility:3},{id:"qa-3",phase:"QA",impactPct:35,year:2023,publishDate:"2023-05-01",source:"Google Testing Blog — ML Test Selection",sourceUrl:"https://testing.googleblog.com/2018/09/efficacy-presubmit.html",dataType:"empirical",description:"Google ML-based test selection (Efficacy Presubmit): reduces required test runs by skipping passing tests while maintaining defect detection, saving significant CI compute resources.",sampleSize:"Google-scale deployment",credibility:3},{id:"qa-4",phase:"QA",impactPct:46,year:2020,publishDate:"2020-01-30",source:"Applitools — Visual AI Hackathon Report",sourceUrl:"https://www.prnewswire.com/news-releases/impact-of-visual-ai-on-test-automation-shows-5-8x-faster-authoring-5-9x-better-test-code-efficiency-and-a-4-6x-increase-in-test-stability-301036643.html",dataType:"empirical",description:"Visual AI Hackathon: 288 quality engineers found Visual AI caught 95% of bugs vs 65% for code-based frameworks (~46% improvement). 5.8x faster test authoring, 4.6x better stability.",sampleSize:"288 quality engineers",credibility:2},{id:"qa-5",phase:"QA",impactPct:28,year:2024,publishDate:"2024-10-01",source:"IEEE — LLMorpheus: LLM-Based Mutation Testing",sourceUrl:"https://ieeexplore.ieee.org/iel8/32/11048386/10977824.pdf",dataType:"empirical",description:"IEEE TSE: LLMorpheus uses LLMs for mutation testing, generating more diverse and realistic mutants than traditional operators. LLM-based approach detects more faulty code patterns.",credibility:3},{id:"qa-6",phase:"QA",impactPct:60,year:2024,publishDate:"2024-06-15",source:"Tricentis/Testim — AI Self-Healing Tests",sourceUrl:"https://www.testim.io/blog/ai-and-quality-assurance-self-healing-processes-to-improve-engineer-experience/",dataType:"vendor",description:"Testim (Tricentis) AI self-healing tests: reduces test maintenance through automatic locator updates when UI changes. Vendor claims up to 60% maintenance reduction for enterprise clients.",credibility:1},{id:"qa-7",phase:"QA",impactPct:50,year:2025,publishDate:"2025-03-15",source:"Tricentis — QA Trends: AI and Agentic Testing",sourceUrl:"https://www.tricentis.com/blog/qa-trends-ai-agentic-testing",dataType:"survey",description:"Tricentis analysis of agentic QA trends: emerging AI testing agents can autonomously generate, execute, and triage test results. Vendor claims 85% defect prediction accuracy.",credibility:2},{id:"qa-8",phase:"QA",impactPct:55,year:2025,publishDate:"2025-06-15",source:"LambdaTest/TestMu AI — Cross-Browser Testing",sourceUrl:"https://www.lambdatest.com/",dataType:"vendor",description:"LambdaTest (now TestMu AI) platform: vendor claims 70% faster test execution (HyperExecute) and 40-70% reduction in manual testing effort through AI-powered KaneAI.",credibility:1},{id:"qa-9",phase:"QA",impactPct:20,year:2025,publishDate:"2025-06-15",source:"Microsoft Engineering — AI Code Reviews at Scale",sourceUrl:"https://devblogs.microsoft.com/engineering-at-microsoft/enhancing-code-quality-at-scale-with-ai-powered-code-reviews/",dataType:"empirical",description:"Microsoft: AI-powered code reviews scaled to 90% of PRs (600K+/month). 10-20% median PR completion time improvement. Qualitative improvements in bug detection before merge.",sampleSize:"600,000+ PRs/month",credibility:3},{id:"qa-10",phase:"QA",impactPct:60,year:2025,publishDate:"2025-06-15",source:"Forrester — Autonomous Testing Platform Landscape",sourceUrl:"https://www.forrester.com/blogs/the-autonomous-testing-platform-vendor-landscape-q2-2025-is-out/",dataType:"survey",description:"Forrester Q2 2025 landscape: autonomous testing platforms achieving significant regression testing time reduction. Market rapidly evolving with multiple enterprise-grade offerings.",credibility:2},{id:"qa-11",phase:"QA",impactPct:70,year:2025,publishDate:"2025-06-15",source:"Square Enix — AI QA Automation Target",sourceUrl:"https://www.videogameschronicle.com/news/square-enix-says-it-wants-generative-ai-to-be-doing-70-of-its-qa-and-debugging-by-the-end-of-2027/",dataType:"anecdotal",description:"Square Enix targets 70% AI-driven QA and debugging automation by end of 2027, representing one of the most ambitious enterprise AI testing commitments publicly announced.",credibility:1},{id:"qa-12",phase:"QA",impactPct:65,year:2025,publishDate:"2025-06-15",source:"Mabl — Benchmarking AI Agent Architectures for Testing",sourceUrl:"https://www.mabl.com/blog/benchmarking-ai-agent-architectures-enterprise-test-automation",dataType:"empirical",description:"Mabl benchmarks AI agent architectures for enterprise test automation. Purpose-built testing agents outperform general-purpose LLMs, achieving higher accuracy on QA-specific tasks.",credibility:2},{id:"ops-1",phase:"DevOps",impactPct:20,year:2023,publishDate:"2023-10-10",source:"DORA Report 2023",sourceUrl:"https://dora.dev/research/2023/dora-report/",dataType:"empirical",description:'DORA 2023: AI impact on DevOps was "in its infancy." Generative organizational culture (not AI tools) was the primary driver of 30% higher performance. Baseline year for AI in DevOps.',sampleSize:"Thousands of teams",credibility:3},{id:"ops-2",phase:"DevOps",impactPct:91,year:2024,publishDate:"2024-06-15",source:"PagerDuty — AIOps Platform",sourceUrl:"https://www.pagerduty.com/platform/aiops/",dataType:"vendor",description:"PagerDuty AIOps: Forrester TEI study reports 91% alert noise reduction. Early access customers see 87% average noise reduction through AI-powered alert correlation and grouping.",credibility:1},{id:"ops-3",phase:"DevOps",impactPct:30,year:2024,publishDate:"2024-06-15",source:"HashiCorp — State of Cloud Strategy 2024",sourceUrl:"https://www.hashicorp.com/en/state-of-the-cloud",dataType:"survey",description:"HashiCorp 2024: 70% of respondents using or planning to use AI for cloud infrastructure. 42% rely on platform teams to standardize operations. AI-assisted IaC gaining traction.",credibility:2},{id:"ops-4",phase:"DevOps",impactPct:28,year:2024,publishDate:"2024-06-15",source:"Google Research — Capacity Planning at Scale",sourceUrl:"https://research.google/pubs/pub45902/",dataType:"empirical",description:"Google research on ML-based capacity planning: intent-based systems improve resource utilization in large-scale distributed systems, reducing over-provisioning and operational waste.",sampleSize:"Google-scale deployment",credibility:3},{id:"ops-5",phase:"DevOps",impactPct:40,year:2025,publishDate:"2025-03-15",source:"Platform Engineering — State of AI 2025",sourceUrl:"https://platformengineering.org/reports/state-of-ai-in-platform-engineering-2025",dataType:"survey",description:"State of AI in Platform Engineering 2025: 88% AI usage reported. 75% use AI for code generation. AI-assisted CI/CD optimization becoming standard in platform engineering teams.",credibility:2},{id:"ops-6",phase:"DevOps",impactPct:38,year:2025,publishDate:"2025-06-15",source:"CNCF — Cloud Native Survey & AI Adoption",sourceUrl:"https://www.cncf.io/reports/the-cncf-annual-cloud-native-survey/",dataType:"survey",description:"CNCF annual survey: leading AI tools gaining adoption in cloud-native ecosystems. AI-powered deployment risk scoring and automated rollback capabilities emerging across platforms.",credibility:2},{id:"ops-7",phase:"DevOps",impactPct:50,year:2026,publishDate:"2026-02-15",source:"Opsera — 2026 AI Coding Impact Benchmark",sourceUrl:"https://www.prnewswire.com/news-releases/new-opsera-report-reveals-how-ai-is-transforming-software-delivery-and-driving-business-outcomes-302673996.html",dataType:"survey",description:"Opsera 2026 benchmark: AI transforming software delivery and driving business outcomes. Autonomous incident detection and remediation agents reducing manual operational overhead.",credibility:2},{id:"ops-8",phase:"DevOps",impactPct:50,year:2026,publishDate:"2026-02-15",source:"Perforce — 2026 State of DevOps",sourceUrl:"https://www.prnewswire.com/news-releases/perforce-2026-state-of-devops-report-indicates-mature-devops-practices-lead-to-ai-success-302695614.html",dataType:"survey",description:"Perforce 2026: mature DevOps practices lead to AI success. Organizations with strong foundations see greater AI-driven operational improvements than those without.",credibility:2},{id:"dr-str-1",phase:"Strategy",impactPct:40,year:2023,publishDate:"2023-06-14",source:"McKinsey Global Institute",sourceUrl:"https://www.mckinsey.com/capabilities/tech-and-ai/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier",dataType:"empirical",description:"McKinsey estimates generative AI could add $2.6–4.4 trillion annually across industries, with knowledge workers gaining up to 40% productivity in decision-support and strategic analysis tasks.",sampleSize:"63 use cases analyzed",credibility:3},{id:"dr-str-2",phase:"Strategy",impactPct:25,year:2023,publishDate:"2023-09-21",source:"Harvard Business School (Jagged Frontier)",sourceUrl:"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321",dataType:"empirical",description:"BCG consultants using GPT-4 completed 12.2% more tasks, were 25.1% faster, and produced 40% higher quality output on strategic analysis tasks in field experiment.",sampleSize:"758 consultants",credibility:3},{id:"dr-str-3",phase:"Strategy",impactPct:37,year:2023,publishDate:"2023-07-14",source:"Noy & Zhang — Science (2023)",sourceUrl:"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4375283",dataType:"empirical",description:"Experimental evidence: ChatGPT reduced time for professional writing tasks by 37% and substantially reduced output quality inequality between workers.",sampleSize:"444 professionals",credibility:3},{id:"dr-str-4",phase:"Strategy",impactPct:20,year:2023,publishDate:"2023-10-11",source:"Gartner GenAI Adoption Forecast",sourceUrl:"https://www.gartner.com/en/newsroom/press-releases/2023-10-11-gartner-says-more-than-80-percent-of-enterprises-will-have-used-generative-ai-apis-or-deployed-generative-ai-enabled-applications-by-2026",dataType:"survey",description:"Gartner predicts >80% of enterprises will deploy GenAI by 2026. Early adopters report ~20% improvement in strategic planning and decision-support efficiency.",credibility:2},{id:"dr-str-5",phase:"Strategy",impactPct:22,year:2023,publishDate:"2023-08-01",source:"McKinsey State of AI 2023 Survey",sourceUrl:"https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2023-generative-AIs-breakout-year",dataType:"survey",description:"One-third of organizations use GenAI regularly in at least one function; high-performing AI organizations report 22% higher revenue from AI-enabled strategy.",sampleSize:"1,684 respondents",credibility:3},{id:"dr-str-6",phase:"Strategy",impactPct:28,year:2024,publishDate:"2024-06-15",source:"Deloitte State of Generative AI 2024",sourceUrl:"https://www.deloitte.com/ce/en/services/consulting/research/state-of-generative-ai-in-enterprise.html",dataType:"survey",description:"Enterprise survey shows organizations achieving measurable ROI from GenAI report 28% faster strategic decision-making and business case development.",credibility:2},{id:"dr-str-7",phase:"Strategy",impactPct:32,year:2024,publishDate:"2024-06-15",source:"Forrester State of Generative AI 2024",sourceUrl:"https://www.forrester.com/report/the-state-of-generative-ai-2024/RES180458",dataType:"survey",description:"Forrester finds enterprises using AI for market analysis and competitive intelligence achieve 32% faster insight generation compared to traditional methods.",credibility:2},{id:"dr-str-8",phase:"Strategy",impactPct:35,year:2025,publishDate:"2024-10-22",source:"Gartner Top Predictions 2025",sourceUrl:"https://www.gartner.com/en/newsroom/press-releases/2024-10-22-gartner-unveils-top-predictions-for-it-organizations-and-users-in-2025-and-beyond",dataType:"survey",description:"Gartner predicts AI-augmented strategy tools will reduce strategic planning cycles by 35% for early-adopting enterprises; agentic AI will reshape IT investment decisions.",credibility:2},{id:"dr-des-1",phase:"Design",impactPct:30,year:2024,publishDate:"2024-06-01",source:"MDPI — ChatGPT in Requirements Engineering",sourceUrl:"https://www.mdpi.com/1999-5903/16/6/180",dataType:"empirical",description:"Comprehensive review finds ChatGPT reduces requirements elicitation and specification time by ~30%, though it introduces consistency challenges requiring human validation.",sampleSize:"Literature review of 50+ studies",credibility:3},{id:"dr-des-2",phase:"Design",impactPct:22,year:2023,publishDate:"2023-04-25",source:"arXiv — ChatGPT Requirements Retrieval",sourceUrl:"https://arxiv.org/abs/2304.12562",dataType:"empirical",description:"Empirical evaluation found ChatGPT achieves 22% improvement over baseline methods on requirements information retrieval tasks across multiple project domains.",sampleSize:"5 projects",credibility:2},{id:"dr-des-3",phase:"Design",impactPct:38,year:2025,publishDate:"2025-06-15",source:"ACM — LLM-Based Product Requirements",sourceUrl:"https://dl.acm.org/doi/epdf/10.1145/3696630.3731673",dataType:"empirical",description:"LLM-based system for generating and validating product requirements reduced PRD creation time by 38% while maintaining stakeholder approval rates.",sampleSize:"24 product teams",credibility:3},{id:"dr-spc-1",phase:"Spec",impactPct:28,year:2024,publishDate:"2024-03-03",source:"arXiv — LLMs for Architectural Design Decisions",sourceUrl:"https://arxiv.org/abs/2403.01709",dataType:"empirical",description:"Study on whether LLMs can generate architectural design decisions found 28% time savings in ADR creation, though human review remains essential for quality assurance.",sampleSize:"100 ADRs evaluated",credibility:2},{id:"dr-spc-2",phase:"Spec",impactPct:32,year:2024,publishDate:"2024-09-15",source:"Springer — ArchMind LLM Design Tool",sourceUrl:"https://link.springer.com/chapter/10.1007/978-3-031-70797-1_21",dataType:"empirical",description:"ArchMind LLM-based tool improved novice architects' quality design decisions by 32% compared to unaided decisions in a controlled evaluation study.",sampleSize:"36 novice architects",credibility:3},{id:"dr-spc-3",phase:"Spec",impactPct:42,year:2024,publishDate:"2024-02-18",source:"arXiv — SpeCrawler (OpenAPI Generation)",sourceUrl:"https://arxiv.org/abs/2402.11625",dataType:"empirical",description:"SpeCrawler uses LLMs to generate OpenAPI specifications from API documentation, reducing spec creation time by 42% versus manual authoring.",sampleSize:"30 API endpoints",credibility:2},{id:"dr-spc-4",phase:"Spec",impactPct:48,year:2025,publishDate:"2025-06-15",source:"ACL Industry — OpenAPI from Documentation",sourceUrl:"https://aclanthology.org/2025.acl-industry.18/",dataType:"empirical",description:"Generating OpenAPI specifications from online API documentation with LLMs achieves 48% time reduction while maintaining specification accuracy above 85%.",sampleSize:"50 APIs",credibility:3},{id:"dr-spc-5",phase:"Spec",impactPct:35,year:2024,publishDate:"2024-06-14",source:"arXiv — Requirements to Code Pipeline",sourceUrl:"https://arxiv.org/html/2406.10101v1",dataType:"empirical",description:"End-to-end pipeline from requirements to OO model to tests to code demonstrates 35% reduction in specification-to-implementation time for well-defined modules.",sampleSize:"20 modules",credibility:2},{id:"dr-dev-1",phase:"Dev",impactPct:26,year:2023,publishDate:"2023-02-14",source:"arXiv — GitHub Copilot Controlled Experiment",sourceUrl:"https://arxiv.org/abs/2302.06590",dataType:"empirical",description:"Controlled experiment measuring Copilot impact: developers completed tasks 55.8% faster; net productivity gain of ~26% after accounting for code review time.",sampleSize:"95 developers",credibility:3},{id:"dr-dev-2",phase:"Dev",impactPct:15,year:2024,publishDate:"2024-10-15",source:"GitHub/Accenture Enterprise RCT",sourceUrl:"https://github.blog/news-insights/research/research-quantifying-github-copilots-impact-in-the-enterprise-with-accenture/",dataType:"empirical",description:"Randomized controlled trial at Accenture: Copilot users merged 15% more PRs per developer, with largest gains for junior and less experienced developers.",sampleSize:"450 developers",credibility:3},{id:"dr-dev-3",phase:"Dev",impactPct:10,year:2024,publishDate:"2024-10-15",source:"GitHub Accenture Customer Story",sourceUrl:"https://github.com/customer-stories/accenture",dataType:"empirical",description:"Accenture enterprise-wide Copilot rollout showed 10% measurable improvement in developer throughput, with strongest gains for junior developers on routine tasks.",sampleSize:"Enterprise-wide deployment",credibility:2},{id:"dr-dev-4",phase:"Dev",impactPct:25,year:2024,publishDate:"2024-10-17",source:"Google AI-Assisted Development RCT",sourceUrl:"https://arxiv.org/abs/2410.12944",dataType:"empirical",description:"Enterprise RCT at Google found AI assistance reduced iteration time by ~25%, with effect concentrated in code editing and debugging tasks rather than design.",sampleSize:"Thousands of Google engineers",credibility:3},{id:"dr-dev-5",phase:"Dev",impactPct:22,year:2025,publishDate:"2025-10-01",source:"DORA Report 2025 — AI in Development",sourceUrl:"https://dora.dev/research/2025/dora-report/",dataType:"empirical",description:"DORA 2025 finds AI-assisted developers show 22% higher throughput but notes potential degradation in change stability metrics without proper safeguards.",sampleSize:"39,000+ respondents",credibility:3},{id:"dr-dev-6",phase:"Dev",impactPct:18,year:2024,publishDate:"2024-06-15",source:"DORA GenAI Special Report",sourceUrl:"https://dora.dev/ai/gen-ai-report/",dataType:"empirical",description:"DORA special report on GenAI impact finds 18% improvement in development speed but warns about increased change failure rate without proper review controls.",sampleSize:"3,000+ teams",credibility:3},{id:"dr-dev-7",phase:"Dev",impactPct:45,year:2023,publishDate:"2023-06-15",source:"McKinsey — Developer Productivity with GenAI",sourceUrl:"https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/unleashing%20developer%20productivity%20with%20generative%20ai/unleashing-developer-productivity-with-generative-ai.pdf",dataType:"empirical",description:"McKinsey found AI coding assistants cut code generation time by up to 45%, with documentation and refactoring tasks seeing 30–50% gains in controlled benchmarks.",sampleSize:"40 developer tasks",credibility:2},{id:"dr-dev-8",phase:"Dev",impactPct:20,year:2024,publishDate:"2024-06-15",source:"Bain — Beyond Code Generation",sourceUrl:"https://www.bain.com/insights/beyond-code-generation-more-efficient-software-development-tech-report-2024/",dataType:"survey",description:"Bain reports 10–30% engineering efficiency gains from GenAI, with median ~20% improvement concentrated in code generation and documentation tasks.",credibility:2},{id:"dr-dev-9",phase:"Dev",impactPct:35,year:2024,publishDate:"2024-06-15",source:"BCG — Scaling GenAI in Software",sourceUrl:"https://www.bcg.com/publications/2024/the-art-of-scaling-genai-in-software",dataType:"survey",description:"BCG survey of engineering leaders shows 20–50% productivity range, with median 35% improvement for teams that successfully scaled GenAI adoption across the SDLC.",sampleSize:"100+ engineering organizations",credibility:2},{id:"dr-dev-10",phase:"Dev",impactPct:33,year:2024,publishDate:"2024-06-15",source:"ScienceDirect — ChatGPT Code Refactoring",sourceUrl:"https://www.sciencedirect.com/science/article/pii/S0957417424004676",dataType:"empirical",description:"Empirical study found ChatGPT performed code refactoring 33% faster than manual approaches, with comparable code quality maintained in 78% of evaluated cases.",sampleSize:"40 refactoring tasks",credibility:3},{id:"dr-dev-11",phase:"Dev",impactPct:26,year:2024,publishDate:"2024-06-15",source:"CACM — Measuring Copilot Impact",sourceUrl:"https://cacm.acm.org/research/measuring-github-copilots-impact-on-productivity/",dataType:"empirical",description:"Large-scale survey and telemetry analysis found GitHub Copilot improves developer-perceived productivity by 26% and measurably reduces time on repetitive coding tasks.",sampleSize:"2,000+ developers",credibility:3},{id:"dr-dev-12",phase:"Dev",impactPct:26,year:2023,publishDate:"2023-06-15",source:"Microsoft Research — Copilot Productivity",sourceUrl:"https://www.microsoft.com/en-us/research/publication/the-impact-of-ai-on-developer-productivity-evidence-from-github-copilot/",dataType:"empirical",description:"Microsoft Research publication page for the controlled Copilot experiment: AI-assisted developers completed tasks 26% faster with measurable productivity gains.",sampleSize:"95 developers",credibility:3},{id:"dr-qa-1",phase:"QA",impactPct:57,year:2023,publishDate:"2023-05-08",source:"arXiv — ChatGPT for Unit Test Generation",sourceUrl:"https://arxiv.org/abs/2305.04207",dataType:"empirical",description:"ChatGPT-generated unit tests achieved 57% line coverage on average, but 22% of tests contained compilation errors requiring manual correction.",sampleSize:"25 Java classes",credibility:2},{id:"dr-qa-2",phase:"QA",impactPct:48,year:2024,publishDate:"2024-06-15",source:"ACM ESEC/FSE — ChatGPT Test Evaluation",sourceUrl:"https://dl.acm.org/doi/epdf/10.1145/3660783",dataType:"empirical",description:"Peer-reviewed evaluation of ChatGPT for unit test generation found 48% speed improvement after iterative refinement with feedback loops on 30 open-source projects.",sampleSize:"30 open-source projects",credibility:3},{id:"dr-qa-3",phase:"QA",impactPct:40,year:2024,publishDate:"2024-01-15",source:"IEEE TSE — LLM Unit Test Generation (Schäfer)",sourceUrl:"https://doi.org/10.1109/TSE.2023.3334955",dataType:"empirical",description:"Systematic evaluation of LLMs for automated unit test generation: 40% improvement in code coverage over baseline, with GPT-4 significantly outperforming GPT-3.5.",sampleSize:"100 functions across 15 projects",credibility:3},{id:"dr-qa-4",phase:"QA",impactPct:45,year:2024,publishDate:"2024-06-26",source:"arXiv — Empirical Study of LLM Unit Tests",sourceUrl:"https://arxiv.org/html/2406.18181v1",dataType:"empirical",description:"Empirical study shows LLMs create test suites 45% faster, but only 68% of generated tests compile and pass without modification — highlighting the verification gap.",sampleSize:"200 methods across 10 projects",credibility:2},{id:"dr-qa-5",phase:"QA",impactPct:15,year:2025,publishDate:"2025-03-15",source:"Veracode — GenAI Code Security Report",sourceUrl:"https://www.veracode.com/resources/analyst-reports/2025-genai-code-security-report/",dataType:"empirical",description:"AI-generated code has security flaws in ~40% of cases; however, AI-powered SAST scanning detects these vulnerabilities 15% faster than traditional tools.",sampleSize:"Analysis of millions of scans",credibility:3},{id:"dr-qa-6",phase:"QA",impactPct:20,year:2024,publishDate:"2024-06-15",source:"Snyk — AI Tool Adoption Survey",sourceUrl:"https://snyk.io/blog/ai-tool-adoption-perceptions-and-realities/",dataType:"survey",description:"56% of developers use AI coding tools; those combining AI code generation with AI-powered security scanning report 20% faster vulnerability remediation times.",sampleSize:"500+ developers",credibility:2},{id:"dr-qa-7",phase:"QA",impactPct:12,year:2026,publishDate:"2026-01-15",source:"SonarSource — Verification Gap Report",sourceUrl:"https://www.sonarsource.com/company/press-releases/sonar-data-reveals-critical-verification-gap-in-ai-coding/",dataType:"survey",description:'SonarSource reveals a critical "verification gap": AI boosts code output but only 12% of teams have adequate automated quality gates for AI-generated code.',sampleSize:"3,000 developers surveyed",credibility:2},{id:"dr-qa-8",phase:"QA",impactPct:25,year:2024,publishDate:"2024-03-15",source:"ScienceDirect — GRACE Vulnerability Detection",sourceUrl:"https://www.sciencedirect.com/science/article/pii/S0164121224000748",dataType:"empirical",description:"GRACE framework empowering LLM-based vulnerability detection achieves 25% higher detection rate than traditional static analysis with fewer false positives.",sampleSize:"8 open-source projects",credibility:3},{id:"dr-qa-9",phase:"QA",impactPct:30,year:2025,publishDate:"2025-02-11",source:"arXiv — LLMs in Software Security Survey",sourceUrl:"https://arxiv.org/pdf/2502.07049",dataType:"empirical",description:"Comprehensive survey finds LLMs improve vulnerability detection by ~30% over traditional tools, with best results in code review and pattern-based detection tasks.",sampleSize:"Meta-analysis of 50+ studies",credibility:3},{id:"dr-ops-1",phase:"DevOps",impactPct:32,year:2024,publishDate:"2024-08-15",source:"Microsoft Research — LLM Incident Triage",sourceUrl:"https://www.microsoft.com/en-us/research/wp-content/uploads/2024/08/ISSRE24_LLM4triage.pdf",dataType:"empirical",description:"LLMs provide accurate and interpretable incident triage with 32% faster mean-time-to-triage compared to rule-based systems, validated in production at Microsoft.",sampleSize:"10,000+ incidents",credibility:3},{id:"dr-ops-2",phase:"DevOps",impactPct:28,year:2024,publishDate:"2024-06-15",source:"Springer — LLM Log Analysis Benchmark",sourceUrl:"https://link.springer.com/article/10.1007/s10922-024-09831-x",dataType:"empirical",description:"Benchmarking LLMs for log analysis shows 28% improvement in anomaly detection accuracy and faster root cause identification versus regex-based approaches.",sampleSize:"15 log datasets",credibility:3},{id:"dr-ops-3",phase:"DevOps",impactPct:38,year:2025,publishDate:"2025-05-28",source:"arXiv — IRCopilot (Automated Incident Response)",sourceUrl:"https://arxiv.org/abs/2505.20945",dataType:"empirical",description:"IRCopilot automated incident response with LLMs reduces mean time to resolution by 38% for common incident categories through automated diagnosis and remediation.",sampleSize:"500 incidents evaluated",credibility:2},{id:"dr-ops-4",phase:"DevOps",impactPct:22,year:2025,publishDate:"2025-06-15",source:"USENIX SOUPS — LLMs in Security Incident Response",sourceUrl:"https://www.usenix.org/system/files/soups2025-kramer.pdf",dataType:"empirical",description:"Study on integrating LLMs into security incident response found 22% faster investigation times, though analysts still override AI recommendations 35% of the time.",sampleSize:"45 security analysts",credibility:3},{id:"dr-ops-5",phase:"DevOps",impactPct:30,year:2025,publishDate:"2025-06-15",source:"MDPI — AI-Augmented SOC Survey",sourceUrl:"https://www.mdpi.com/2624-800X/5/4/95",dataType:"survey",description:"Survey of LLMs and agents for security operations finds 30% average improvement in alert triage speed and reduced analyst fatigue in AI-augmented SOCs.",sampleSize:"Literature review of 80+ papers",credibility:2},{id:"dr-ops-6",phase:"DevOps",impactPct:35,year:2024,publishDate:"2024-06-15",source:"Uber Engineering — GenAI in Operations",sourceUrl:"https://www.uber.com/blog/the-transformative-power-of-generative-ai/",dataType:"anecdotal",description:"Uber reports 35% reduction in operational toil hours through GenAI-powered automation of log analysis, alert correlation, and runbook execution in production.",credibility:2},{id:"siili-1",phase:"Dev",impactPct:40,year:2025,publishDate:"2025-03-01",source:"Aalto University / Siili Solutions RCT",sourceUrl:"https://aaltodoc.aalto.fi/items/826ea826-a839-40c5-a543-e285c6932fb4",dataType:"empirical",description:"Three-arm randomized controlled trial at Siili Solutions: developers with GenAI access completed tasks 40.2% faster. GPT-4 alone cut time by 25.1% and lifted quality by 38%. Structured prompt-engineering training raised quality to 42.5% over control.",sampleSize:"25 developers, 130 task observations",credibility:3},{id:"siili-2",phase:"Dev",impactPct:26,year:2025,publishDate:"2025-03-01",source:"Aalto University / Siili Solutions RCT",sourceUrl:"https://aaltodoc.aalto.fi/items/826ea826-a839-40c5-a543-e285c6932fb4",dataType:"empirical",description:"Code quality was 26.2% higher per expert evaluation in the AI-assisted group. Adding prompt-engineering training further improved quality, demonstrating that structured AI adoption yields stronger gains than ad-hoc use.",sampleSize:"25 developers, 130 task observations",credibility:3},{id:"siili-3",phase:"Dev",impactPct:40,year:2024,publishDate:"2025-03-01",source:"Siili Solutions — AI-Powered Development Whitepaper",sourceUrl:"https://campaign.siili.com/ai-powered-development-whitepaper",dataType:"empirical",description:"Siili's internal study: tasks completed using AI tools (Copilot, ChatGPT, Claude) were on average 40% faster than traditional methods across junior to senior developers.",credibility:2},{id:"siili-4",phase:"Dev",impactPct:76,year:2024,publishDate:"2025-03-01",source:"Siili Solutions — AI-Powered Development Whitepaper",sourceUrl:"https://campaign.siili.com/ai-powered-development-whitepaper",dataType:"empirical",description:"Frontend feature development saw up to 175.9% faster task completion with AI tools. Code quality improved by 89.7% on average. Over 87% of participants reported positive experiences with reduced cognitive load.",credibility:2},{id:"siili-5",phase:"QA",impactPct:40,year:2024,publishDate:"2025-03-01",source:"Siili Solutions — AI-Powered Development Whitepaper",sourceUrl:"https://campaign.siili.com/ai-powered-development-whitepaper",dataType:"empirical",description:"Test writing showed a 40% increase in quality scores when using AI tools. AI-assisted developers produced more comprehensive test suites with better edge case coverage.",credibility:2},{id:"siili-6",phase:"Spec",impactPct:80,year:2024,publishDate:"2025-03-01",source:"Siili Solutions — AI-Powered Development Whitepaper",sourceUrl:"https://campaign.siili.com/ai-powered-development-whitepaper",dataType:"empirical",description:"Documentation time was cut by 80% on average while improving clarity and comprehensiveness. AI tools excelled at generating structured technical documentation from code.",credibility:2},{id:"siili-7",phase:"Dev",impactPct:67,year:2024,publishDate:"2024-08-13",source:"Siili Solutions — AI vs Traditional Comparison",sourceUrl:"https://www.siili.com/stories/ai-assisted-software-development-vs-the-traditional-way",dataType:"empirical",description:"Controlled comparison: AI team (using Copilot + GPT-4) built 3 applications in the time the traditional team built 1. The AI team estimated 90% of their code was AI-generated.",sampleSize:"2 teams of 4–5 members, 2-week sprint",credibility:2},{id:"siili-8",phase:"Dev",impactPct:50,year:2025,publishDate:"2025-03-01",source:"Siili Solutions — The AI Ripple Effect",sourceUrl:"https://campaign.siili.com/ai-ripple-effect",dataType:"empirical",description:"AI-assisted teams deliver 2x faster with 40% higher code quality. However, AI speeds up coding but creates new bottlenecks in reviews, QA, and management approval processes.",credibility:2},{id:"siili-9",phase:"QA",impactPct:40,year:2025,publishDate:"2025-03-01",source:"Siili Solutions — The AI Ripple Effect",sourceUrl:"https://campaign.siili.com/ai-ripple-effect",dataType:"empirical",description:'Code quality improved by 40% with increased robustness, readability, and alignment with best practices. But the "ripple effect" shifts bottlenecks from coding to acceptance and verification processes.',credibility:2},{id:"siili-10",phase:"Dev",impactPct:38,year:2024,publishDate:"2024-08-13",source:"Siili Solutions — Strategy Announcement",sourceUrl:"https://www.globenewswire.com/news-release/2024/08/13/2928907/0/en/Siili-Solutions-New-strategy-strengthens-position-in-AI-powered-digital-development-and-in-AI-solutions.html",dataType:"vendor",description:"Siili strategy announcement: tasks completed up to 37.5% faster with AI-enhanced productivity supported by developer AI training programs across the organization.",credibility:1},{id:"r2-str-1",phase:"Strategy",impactPct:30,year:2025,publishDate:"2025-06-15",source:"Medium — AI Changing Product Management",sourceUrl:"https://medium.com/@ashume/how-ai-software-development-is-changing-product-management-in-2025-real-examples-b7ed1af7a988",dataType:"anecdotal",description:"AI in product development reduces time-to-market by 20–40% through automated market analysis, competitive intelligence, and accelerated validation cycles.",credibility:1},{id:"r2-str-2",phase:"Strategy",impactPct:25,year:2025,publishDate:"2025-06-15",source:"Medium — AI Changing Product Management",sourceUrl:"https://medium.com/@ashume/how-ai-software-development-is-changing-product-management-in-2025-real-examples-b7ed1af7a988",dataType:"anecdotal",description:"Development cost reduction of 20–30% achieved through AI-augmented product development processes, reducing manual research and iteration overhead.",credibility:1},{id:"r2-str-3",phase:"Strategy",impactPct:91,year:2025,publishDate:"2025-06-15",source:"Forrester 2025 — Emerging AI Technologies",sourceUrl:"https://www.makebot.ai/blog-en/top-emerging-ai-technologies-2025---forrester-report",dataType:"survey",description:"Content creation time reduced by 91% when combining AI generation with human oversight, enabling rapid production of strategic documents, proposals, and business analyses.",credibility:2},{id:"r2-str-4",phase:"Strategy",impactPct:65,year:2024,publishDate:"2024-08-15",source:"McKinsey State of AI 2024",sourceUrl:"https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-2024",dataType:"survey",description:"~65% of organizations now regularly use generative AI, nearly doubling from 33% in 2023. Adoption metric reflecting mainstream enterprise AI integration.",credibility:3},{id:"r2-str-5",phase:"Strategy",impactPct:75,year:2024,publishDate:"2024-04-11",source:"Gartner — AI Code Assistants Forecast",sourceUrl:"https://www.gartner.com/en/newsroom/press-releases/2024-04-11-gartner-says-75-percent-of-enterprise-software-engineers-will-use-ai-code-assistants-by-2028",dataType:"survey",description:"Gartner predicts 75% of enterprise software engineers will use AI code assistants by 2028, up from <10% in early 2023. Critical for strategic workforce and tooling planning.",credibility:3},{id:"r2-des-1",phase:"Design",impactPct:80,year:2025,publishDate:"2025-06-15",source:"Visualping — AI Tools for PMs",sourceUrl:"https://visualping.io/blog/ai-tools-for-product-managers",dataType:"anecdotal",description:"AI-powered PRD generation produces first-draft product requirements in minutes instead of hours/days, compressing the specification-to-design cycle by an order of magnitude.",credibility:1},{id:"r2-des-2",phase:"Design",impactPct:85,year:2025,publishDate:"2025-06-15",source:"Medium — AI Changing Product Management",sourceUrl:"https://medium.com/@ashume/how-ai-software-development-is-changing-product-management-in-2025-real-examples-b7ed1af7a988",dataType:"anecdotal",description:"Idea-to-functional-prototype cycle compressed to under 24 hours (from weeks) using AI prototyping tools like Lovable, Bolt, and Figma Make, collapsing the traditional linear workflow.",credibility:1},{id:"r2-des-3",phase:"Design",impactPct:50,year:2025,publishDate:"2025-06-15",source:"Visualping — AI Tools for PMs",sourceUrl:"https://visualping.io/blog/ai-tools-for-product-managers",dataType:"anecdotal",description:"User research synthesis accelerated 10–50x for large feedback sets, enabling product teams to process thousands of user inputs in hours instead of weeks of manual analysis.",credibility:1},{id:"r2-des-4",phase:"Design",impactPct:60,year:2025,publishDate:"2025-06-15",source:"Figma Make — AI Design Tools",sourceUrl:"https://www.figma.com/solutions/ai-prd-generator/",dataType:"vendor",description:"AI design tools generate multiple UI/UX variations from parameters and natural language prompts. Non-engineers can now turn PRDs into working interactive prototypes directly.",credibility:1},{id:"r2-des-5",phase:"Design",impactPct:40,year:2025,publishDate:"2025-06-15",source:"monday.com — AI for Product Managers",sourceUrl:"https://monday.com/blog/rnd/ai-for-product-managers/",dataType:"vendor",description:"AI tools generate functional PRDs from meeting notes and transcripts, automating translation from stakeholder discussions to structured product requirements documents.",credibility:1},{id:"r2-spc-1",phase:"Spec",impactPct:40,year:2025,publishDate:"2025-06-15",source:"Zencoder — AI Code Generation Trends",sourceUrl:"https://zencoder.ai/blog/ai-code-generation-trends-2024",dataType:"survey",description:"Technical documentation generation time reduced by 30–50% using AI assistance, covering API docs, architecture decision records, and system design specifications.",credibility:2},{id:"r2-spc-2",phase:"Spec",impactPct:15,year:2025,publishDate:"2025-06-15",source:"Qodo — State of AI Code Quality 2025",sourceUrl:"https://www.qodo.ai/reports/state-of-ai-code-quality/",dataType:"survey",description:"Refactoring tasks show the highest AI context miss rate among all task types. Only 3.8% of developers report both low hallucination rates and high confidence in shipping AI-generated architectural code.",credibility:2},{id:"r2-spc-3",phase:"Spec",impactPct:10,year:2025,publishDate:"2025-06-15",source:"Qodo — State of AI Code Quality 2025",sourceUrl:"https://www.qodo.ai/reports/state-of-ai-code-quality/",dataType:"survey",description:"Senior developers report more AI context pain than juniors (52% vs 41%). Deeper mental models reveal gaps AI fails to match in complex architecture and specification decisions.",credibility:2},{id:"r2-dev-1",phase:"Dev",impactPct:26,year:2024,publishDate:"2025-09-29",source:"Longitudinal Copilot Study (arXiv)",sourceUrl:"https://arxiv.org/pdf/2509.20353",dataType:"empirical",description:"Longitudinal A/B test across 3 companies (including Microsoft and Accenture): Copilot increased completed tasks by 26.08% with sustained gains over multiple months.",sampleSize:"RCT across 3 companies",credibility:3},{id:"r2-dev-2",phase:"Dev",impactPct:11,year:2024,publishDate:"2024-06-15",source:"Harness SEI — Copilot Case Study",sourceUrl:"https://www.harness.io/blog/the-impact-of-github-copilot-on-developer-productivity-a-case-study",dataType:"empirical",description:"Real-world Copilot deployment: 10.6% PR throughput increase and 3.5-hour cycle time reduction (2.4% improvement). More modest than lab findings, reflecting production complexity.",sampleSize:"50 developers",credibility:2},{id:"r2-dev-3",phase:"Dev",impactPct:51,year:2025,publishDate:"2025-06-15",source:"Second Talent — GitHub Copilot Statistics",sourceUrl:"https://www.secondtalent.com/resources/github-copilot-statistics/",dataType:"survey",description:"Developers self-report coding 51% faster with Copilot. Suggestion acceptance rate averages ~30%. Ramp-up to full productivity takes approximately 11 weeks.",credibility:2},{id:"r2-dev-4",phase:"Dev",impactPct:-19,year:2025,publishDate:"2025-07-12",source:"METR Study (arXiv 2507.09089)",sourceUrl:"https://arxiv.org/abs/2507.09089",dataType:"empirical",description:"CONTRARIAN: Rigorous RCT found experienced open-source developers were 19% SLOWER with AI tools on familiar, complex codebases — counter to most lab findings on simpler tasks.",sampleSize:"16 developers, 246 tasks",credibility:3},{id:"r2-dev-5",phase:"Dev",impactPct:110,year:2025,publishDate:"2025-06-15",source:"McKinsey/Jellyfish — AI in Software Dev",sourceUrl:"https://www.mckinsey.com/capabilities/mckinsey-technology/our-insights/measuring-ai-in-software-development-interview-with-jellyfish-ceo-andrew-lau",dataType:"survey",description:"Companies with 80–100% Copilot adoption report over 110% productivity gains. Requires near-universal team adoption and workflow redesign, not just tool deployment.",sampleSize:"Enterprise telemetry",credibility:2},{id:"r2-dev-6",phase:"Dev",impactPct:23,year:2025,publishDate:"2025-06-15",source:"McKinsey — Unlocking Value of AI in Software Dev",sourceUrl:"https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/unlocking-the-value-of-ai-in-software-development",dataType:"survey",description:"Survey of 300 companies: top AI performers report 16–30% team productivity improvement. Bottom performers see minimal gains. Process redesign differentiates outcomes.",sampleSize:"300 companies",credibility:3},{id:"r2-dev-7",phase:"Dev",impactPct:38,year:2025,publishDate:"2025-06-15",source:"McKinsey — Unlocking Value of AI in Software Dev",sourceUrl:"https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/unlocking-the-value-of-ai-in-software-development",dataType:"survey",description:"Top performers report 31–45% software quality improvement from AI integration. Quality gains often exceed speed gains but require robust review processes and testing.",sampleSize:"300 companies",credibility:3},{id:"r2-dev-8",phase:"Dev",impactPct:40,year:2025,publishDate:"2025-06-15",source:"Forrester 2025 — Emerging AI Technologies",sourceUrl:"https://www.makebot.ai/blog-en/top-emerging-ai-technologies-2025---forrester-report",dataType:"survey",description:"Forrester reports AI-assisted coding achieves up to 40% speed improvement and 30% fewer errors for well-integrated development workflows.",credibility:2},{id:"r2-dev-9",phase:"Dev",impactPct:0,year:2024,publishDate:"2024-09-17",source:"Uplevel — Copilot Productivity Study",sourceUrl:"https://visualstudiomagazine.com/articles/2024/09/17/another-report-weighs-in-on-github-copilot-dev-productivity.aspx",dataType:"empirical",description:"Study of 800 developers: Copilot users had higher bug rates with no measurable throughput improvement. Contradicts vendor-funded studies showing significant productivity gains.",sampleSize:"800 developers",credibility:2},{id:"r2-dev-10",phase:"Dev",impactPct:-10,year:2024,publishDate:"2024-06-15",source:"LinearB/GitClear — AI Code Churn Analysis",sourceUrl:"https://linearb.io/blog/is-github-copilot-worth-it",dataType:"empirical",description:"AI-generated code has 41% higher churn rate than human-written code (GitClear 2024 data). Speed gains partially offset by increased rework and technical debt accumulation.",credibility:2},{id:"r2-dev-11",phase:"Dev",impactPct:56,year:2024,publishDate:"2022-09-07",source:"GitHub Blog — Copilot Productivity & Happiness",sourceUrl:"https://github.blog/news-insights/research/research-quantifying-github-copilots-impact-on-developer-productivity-and-happiness/",dataType:"empirical",description:"GitHub research: 88% code retention rate for AI suggestions, 87% report mental effort preservation for repetitive tasks, 60–75% report increased job satisfaction with Copilot.",sampleSize:"95 professional developers",credibility:2},{id:"r2-dev-12",phase:"Dev",impactPct:29,year:2025,publishDate:"2025-06-01",source:"Stack Overflow Developer Survey 2025 — AI",sourceUrl:"https://survey.stackoverflow.co/2025/ai/",dataType:"survey",description:"Trust paradox: 84% of developers use AI tools (up from 70% in 2023), but trust in AI accuracy dropped to 29% (from 43%). Positive sentiment fell from 77% (2023) to 60% (2025).",sampleSize:"49,000+ developers",credibility:3},{id:"r2-dev-13",phase:"Dev",impactPct:20,year:2025,publishDate:"2025-06-15",source:"VentureBeat — Hidden Productivity Tax of AI Code",sourceUrl:"https://venturebeat.com/ai/stack-overflow-data-reveals-the-hidden-productivity-tax-of-almost-right-ai-code",dataType:"survey",description:'The "almost right" problem: 66% struggle with AI code that is close but misses the mark. 45% say debugging AI code takes longer than writing from scratch. 35% turn to Stack Overflow after AI fails.',credibility:2},{id:"r2-qa-1",phase:"QA",impactPct:16,year:2025,publishDate:"2025-06-15",source:"QAble — Is AI Helping Testing?",sourceUrl:"https://www.qable.io/blog/is-ai-really-helping-to-improve-the-testing",dataType:"survey",description:"75% of QA organizations identify AI testing as strategic priority, but only 16% have adopted it (65–70% still in pilot). Large gap between aspiration and actual implementation.",credibility:2},{id:"r2-qa-2",phase:"QA",impactPct:45,year:2024,publishDate:"2024-06-15",source:"Virtuoso QA — AI Test Automation Future",sourceUrl:"https://www.virtuosoqa.com/post/ai-test-automation-future",dataType:"survey",description:"Fortune 500 AI testing adoption at 45%, startups lead at 62%. 35% of enterprise budgets shifting to AI testing platforms. 80% predicted AI-augmented testing tools by 2027.",credibility:2},{id:"r2-qa-3",phase:"QA",impactPct:50,year:2025,publishDate:"2025-06-15",source:"Pandhare — Future of Software Test Automation (ResearchGate)",sourceUrl:"https://www.researchgate.net/publication/391806293_Future_of_Software_Test_Automation_Using_AIML",dataType:"empirical",description:"Vendor claims of 50% faster testing and 30% more bug detection. By 2027, 65%+ of enterprise testing projected to involve AI/ML. No standardized measurement framework exists yet.",credibility:2},{id:"r2-qa-4",phase:"QA",impactPct:25,year:2024,publishDate:"2024-06-15",source:"DeviQA — AI Changes QA 2025",sourceUrl:"https://www.deviqa.com/blog/how-ai-changes-qa-expectations-in-2025/",dataType:"survey",description:"Top AI testing use cases: test case creation (25%), test case optimization (23%), automated regression (19%). Most teams use AI as supplement, not replacement for manual testing.",credibility:2},{id:"r2-qa-5",phase:"QA",impactPct:95,year:2025,publishDate:"2025-06-15",source:"Virtuoso QA — AI Test Maintenance Claims",sourceUrl:"https://www.virtuosoqa.com/post/ai-test-automation-future",dataType:"vendor",description:"AI-native platforms claim up to 95% test maintenance reduction through self-healing tests. Only achievable on new platforms — bolting AI onto legacy frameworks shows much smaller gains.",credibility:1},{id:"r2-qa-6",phase:"QA",impactPct:80,year:2025,publishDate:"2025-03-15",source:"Tricentis — AI Trends in Testing 2025",sourceUrl:"https://www.tricentis.com/blog/5-ai-trends-shaping-software-testing-in-2025",dataType:"survey",description:"80% of software teams plan to use AI in testing by 2025. Gartner projects 80% enterprise AI-augmented testing tools by 2027 and 33% agentic AI in enterprise software by 2028.",credibility:2},{id:"r2-qa-7",phase:"QA",impactPct:45,year:2025,publishDate:"2025-06-15",source:"QAble — Manual Testing Persistence",sourceUrl:"https://www.qable.io/blog/is-ai-really-helping-to-improve-the-testing",dataType:"survey",description:"45% of QA practitioners believe manual testing is irreplaceable. Human element remains critical for exploratory testing, UX evaluation, and edge case identification.",credibility:2},{id:"r2-qa-8",phase:"QA",impactPct:-5,year:2024,publishDate:"2024-06-15",source:"Rainforest QA — AI in Testing Report 2025",sourceUrl:"https://www.rainforestqa.com/blog/ai-in-software-testing-report-2025",dataType:"empirical",description:"Early AI testing adopters initially spent MORE time on maintenance, not less. AI-generated tests required significant human review and correction before achieving reliability.",credibility:2},{id:"r2-ops-1",phase:"DevOps",impactPct:67,year:2024,publishDate:"2024-06-15",source:"AmericanChase — AI in DevOps",sourceUrl:"https://americanchase.com/ai-in-deveops/",dataType:"survey",description:"Release cycle reduction of 67% with AI in DevOps pipelines (citing Forrester 2024 State of DevOps). Primarily driven by automated testing, deployment, and pipeline optimization.",credibility:2},{id:"r2-ops-2",phase:"DevOps",impactPct:43,year:2024,publishDate:"2024-06-15",source:"AmericanChase — AI in DevOps",sourceUrl:"https://americanchase.com/ai-in-deveops/",dataType:"survey",description:"Production incidents reduced by 43% through AI-assisted operations (citing IBM 2024 DevSecOps Survey). Reduction primarily from automated human-error prevention.",credibility:2},{id:"r2-ops-3",phase:"DevOps",impactPct:31,year:2025,publishDate:"2025-06-15",source:"AmericanChase — AI in DevOps",sourceUrl:"https://americanchase.com/ai-in-deveops/",dataType:"survey",description:"Mature AI DevOps implementations achieve 31% average TCO reduction for enterprise applications (citing Deloitte 2025 Technology Cost Survey).",credibility:2},{id:"r2-ops-4",phase:"DevOps",impactPct:30,year:2025,publishDate:"2025-06-15",source:"WebProNews — AI Agents in CI/CD",sourceUrl:"https://www.webpronews.com/ai-agents-revolutionize-ci-cd-inside-devops-2025-overhaul/",dataType:"empirical",description:"GitLab AI tools deliver 30% faster releases across 1.5 million developers. AI agents automate CI/CD pipeline optimization and failure prediction.",sampleSize:"1.5 million developers",credibility:2},{id:"r2-ops-5",phase:"DevOps",impactPct:54,year:2025,publishDate:"2025-10-29",source:"Gartner — I&O Leaders AI Survey",sourceUrl:"https://www.gartner.com/en/newsroom/press-releases/2025-10-29-gartner-survey-54-percent-of-infrastructure-and-operations-leaders-are-adopting-artificial-intelligence-to-cut-costs",dataType:"survey",description:"54% of I&O leaders adopting AI for cost optimization. Top barriers: lack of budget (50%) and integration difficulties (48%). Strategic investment, not bolt-on adoption, drives ROI.",sampleSize:"253 I&O leaders",credibility:3},{id:"r2-ops-6",phase:"DevOps",impactPct:15,year:2025,publishDate:"2025-10-01",source:"Google DORA Report 2025",sourceUrl:"https://cloud.google.com/blog/products/ai-machine-learning/announcing-the-2025-dora-report",dataType:"empirical",description:"DORA 2025: AI adoption positively correlates with delivery throughput but NEGATIVELY with deployment stability. AI amplifies existing organizational dynamics — both strengths and weaknesses.",sampleSize:"39,000+ respondents",credibility:3},{id:"r2-ops-7",phase:"DevOps",impactPct:35,year:2025,publishDate:"2025-06-15",source:"Softjourn — AI Transforming DevOps",sourceUrl:"https://softjourn.com/insights/how-ai-is-transforming-devops",dataType:"survey",description:"DevOps market projected to grow from $14.95B (2025) to $37.33B by 2029. AI-driven deployment automation, monitoring, and incident response driving 2.5x market expansion.",credibility:2},{id:"r2-ops-8",phase:"DevOps",impactPct:33,year:2025,publishDate:"2025-03-15",source:"Gartner/Tricentis — Agentic AI Forecast",sourceUrl:"https://www.tricentis.com/blog/5-ai-trends-shaping-software-testing-in-2025",dataType:"survey",description:"Gartner projects 33% of enterprise software will incorporate agentic AI by 2028 (up from <1% in 2024). Autonomous deployment, monitoring, and incident response agents emerging.",credibility:3},{id:"sm-dev-1",phase:"Dev",impactPct:95,year:2025,publishDate:"2025-02-02",source:"X/Twitter — @karpathy (Andrej Karpathy)",sourceUrl:"https://x.com/karpathy/status/1886192184808149383",dataType:"anecdotal",description:'OpenAI co-founder coins "vibe coding": "fully give in to the vibes, embrace exponentials, and forget that the code even exists." Describes accepting all AI suggestions without reading diffs, using voice-to-code via SuperWhisper with Cursor Composer + Claude Sonnet.',credibility:2},{id:"sm-dev-2",phase:"Dev",impactPct:90,year:2025,publishDate:"2025-03-22",source:"X/Twitter — @karpathy (Andrej Karpathy)",sourceUrl:"https://x.com/karpathy/status/1903671737780498883",dataType:"anecdotal",description:'Karpathy: "I just vibe coded a whole iOS app in Swift (without having programmed in Swift before) and now ~1 hour later it\'s actually running on my physical phone." Built a working iOS app in an unfamiliar language in ~1 hour using AI assistance.',credibility:2},{id:"sm-dev-3",phase:"Dev",impactPct:98,year:2025,publishDate:"2025-02-15",source:"X/Twitter — @levelsio (Pieter Levels)",sourceUrl:"https://x.com/levelsio/status/1893385114496766155",dataType:"anecdotal",description:'Solo indie hacker built fly.pieter.com — a 3D multiplayer flight simulator — 100% with Cursor in ~3 hours, with no prior game development experience. "I\'ve never ever made a game before." Hit $1M ARR in 17 days from ad revenue, endorsed by Elon Musk.',credibility:1},{id:"sm-str-1",phase:"Strategy",impactPct:95,year:2025,publishDate:"2025-03-01",source:"X/Twitter — @levelsio (Pieter Levels)",sourceUrl:"https://x.com/levelsio/status/1899596115210891751",dataType:"anecdotal",description:"fly.pieter.com went from $0 to $1M ARR in just 17 days ($87K MRR). A vibe-coded browser game by a solo founder with no game dev background achieved 320,000 players. Revenue reached $138K/month by November 2025.",credibility:2},{id:"sm-dev-4",phase:"Dev",impactPct:99,year:2025,publishDate:"2025-06-15",source:"X/Twitter — @AlexFinnX (Alex Finn)",sourceUrl:"https://x.com/AlexFinnX/status/1931435156235317369",dataType:"anecdotal",description:'Non-developer built Creator Buddy (AI content coaching SaaS) entirely with Claude Code — "0 lines of code written." App reached $300K ARR with 500 paying subscribers within 2 weeks of launch. Claims vibe coded for 2,639 hours total in 2025.',credibility:1},{id:"sm-str-2",phase:"Strategy",impactPct:90,year:2025,publishDate:"2025-12-15",source:"X/Twitter — @AlexFinnX (Alex Finn)",sourceUrl:"https://x.com/AlexFinn/status/2005793440333000794",dataType:"anecdotal",description:"2025 wrapped: Built first SaaS to $300K ARR with Claude Code, 0 lines of code. Grew vibe coding YouTube to 60K subscribers. Launched world's first Vibe Coding Academy. Solo non-technical founder building and monetizing with AI alone.",credibility:1},{id:"sm-dev-5",phase:"Dev",impactPct:85,year:2025,publishDate:"2025-01-10",source:"X/Twitter — @mckaywrigley (McKay Wrigley)",sourceUrl:"https://x.com/mckaywrigley/status/1827146031144038789",dataType:"anecdotal",description:"AI influencer cancelled 7 B2B SaaS subscriptions and replaced 100% of their value in ~6 hours (one night) using Cursor + o1 Pro. Two apps fully replicated in single prompts, five more in a few Cursor Composer iterations. Claims $7,500+/year savings.",credibility:1},{id:"sm-dev-6",phase:"Dev",impactPct:95,year:2025,publishDate:"2025-09-15",source:"X/Twitter + TechCrunch — Maor Shlomo (Base44)",sourceUrl:"https://techcrunch.com/2025/06/18/6-month-old-solo-owned-vibe-coder-base44-sells-to-wix-for-80m-cash/",dataType:"anecdotal",description:"Solo founder built Base44, an AI app-builder platform, bootstrapped with no team. Reached 250K users and $189K monthly profit in 6 months. Sold to Wix for $80M cash — one of the fastest bootstrapped exits in tech history.",credibility:2},{id:"sm-dev-7",phase:"Dev",impactPct:99,year:2025,publishDate:"2025-06-15",source:"X/Twitter + 20VC — Edwin Chen (Surge CEO)",sourceUrl:"https://finance.yahoo.com/news/10x-engineer-old-news-surges-131630443.html",dataType:"anecdotal",description:'Surge CEO (TIME 100 AI 2025) claims AI creates "100x engineers." Says AI coding tools compound 2-3x speed, 2-3x focus, and 2-3x fewer distractions into 100x productivity. Predicts billion-dollar single-person companies. Surge reached $1B revenue with no VC funding.',credibility:1},{id:"sm-dev-8",phase:"Dev",impactPct:99,year:2026,publishDate:"2026-01-23",source:"X/Twitter — Michael Truell (Cursor CEO)",sourceUrl:"https://fortune.com/2026/01/23/cursor-built-web-browser-with-swarm-ai-agents-powered-openai/",dataType:"anecdotal",description:"Cursor CEO demonstrated AI agents building a web browser from scratch: 3M+ lines of Rust code, custom rendering engine, HTML/CSS parser, layout engine, and JS VM — running autonomously for 1 week with zero human intervention. Used GPT-5.2 swarm agents.",credibility:2},{id:"sm-dev-9",phase:"Dev",impactPct:80,year:2025,publishDate:"2025-10-01",source:"X/Twitter — @bentossell (Ben Tossell)",sourceUrl:"https://x.com/bentossell",dataType:"anecdotal",description:'No-code pioneer and Ben\'s Bites founder reports spending "3 billion tokens in 4 months" using Claude Code as a terminal agent. Self-described vibe-coder building production software without traditional coding skills. Built 7-figure AI education business.',credibility:1},{id:"sm-dev-10",phase:"Dev",impactPct:70,year:2025,publishDate:"2025-03-14",source:"X/Twitter — @jonst0kes (Jon Stokes)",sourceUrl:"https://x.com/jonst0kes/status/1895976084853956763",dataType:"anecdotal",description:'Ars Technica co-founder: "I thought vibe coding was a dumb X thing until I did it today with Claude Code and shipped an amazing refactor." Reports guiding AI through complex decision trees after a week of deep problem analysis. "If you\'re not doing it you will lose to people who do."',credibility:1},{id:"sm-dev-11",phase:"Dev",impactPct:-19,year:2025,publishDate:"2025-06-15",source:"LinkedIn/Blog — Suff Syed (The Vibe Coders Are Lying)",sourceUrl:"https://www.suffsyed.com/futurememo/the-vibe-coders-are-lying-to-you",dataType:"anecdotal",description:"Skeptical analysis: No verified solo vibe-coded product by a non-engineer has exceeded $5-10M ARR with durable retention and enterprise reliability. Argues most viral claims lack post-launch sustainability data and conflate initial launch with sustained business.",credibility:2},{id:"sm-qa-1",phase:"QA",impactPct:-15,year:2025,publishDate:"2025-12-01",source:"X/Twitter — Michael Truell (Cursor CEO) — Vibe Coding Warning",sourceUrl:"https://fortune.com/2025/12/25/cursor-ceo-michael-truell-vibe-coding-warning-generative-ai-assistant/",dataType:"anecdotal",description:"Cursor CEO warns: \"If you close your eyes and don't look at the code and have AIs build things with shaky foundations, as you add another floor... things start to crumble.\" Likens vibe coding to building a house without knowing what's behind the walls.",credibility:2},{id:"sm-dev-12",phase:"Dev",impactPct:80,year:2025,publishDate:"2025-03-01",source:"X/Twitter — @levelsio — 2025 Vibe Coding Game Jam",sourceUrl:"https://x.com/levelsio/status/1901660771505021314",dataType:"anecdotal",description:"Pieter Levels organized the first Vibe Coding Game Jam: 7-day deadline, anyone can enter, at least 80% of code must be AI-generated. Games must be web-accessible, free-to-play. Demonstrated community-scale adoption of AI-first development.",credibility:1},{id:"sm-str-3",phase:"Strategy",impactPct:85,year:2025,publishDate:"2025-06-15",source:"LinkedIn — Alex Finn (AI-Powered SaaS)",sourceUrl:"https://www.linkedin.com/posts/alex-finn-1848684a_a-year-ago-i-started-building-a-side-hustle-activity-7302787746144608256-MseN",dataType:"anecdotal",description:'LinkedIn post: "How I quit my job with AI and built a $315K app." Alex Finn documents journey from content creator to solo SaaS founder using Claude Code. Zero programming background, 10-month timeline from prototype to six-figure ARR.',credibility:1},{id:"sm-spec-1",phase:"Spec",impactPct:40,year:2025,publishDate:"2025-03-14",source:"LinkedIn — Addy Osmani (Vibe Coding vs AI-Assisted Engineering)",sourceUrl:"https://www.linkedin.com/posts/addyosmani_ai-programming-softwareengineering-activity-7368168236628013056-y20E",dataType:"anecdotal",description:'Google Chrome engineering lead distinguishes "vibe coding" from "AI-assisted engineering." Argues professional AI-assisted development requires clear specs, architectural planning, and code review — not blind acceptance. Nuanced take contrasting hype with disciplined practice.',credibility:2},{id:"y26-str-1",phase:"Strategy",impactPct:25,year:2026,publishDate:"2026-01-15",source:"Deloitte — State of AI in the Enterprise 2026",sourceUrl:"https://www.deloitte.com/us/en/what-we-do/capabilities/applied-artificial-intelligence/content/state-of-ai-in-the-enterprise.html",dataType:"survey",description:"Deloitte 2026: 66% of organizations report achieving productivity/efficiency gains from AI; 34% using AI to deeply transform operations. Only 20% achieving revenue growth from AI despite 74% hoping to — pointing to a strategy-execution gap.",sampleSize:"3,235 leaders across 24 countries",credibility:3},{id:"y26-str-2",phase:"Strategy",impactPct:20,year:2026,publishDate:"2026-01-15",source:"Morgan Stanley — AI in Software Development",sourceUrl:"https://www.morganstanley.com/insights/articles/ai-software-development-industry-growth",dataType:"vendor",description:"Morgan Stanley Research: CIOs plan to increase software spending by 3.9% in 2026. 30% of AI adopters reported quantifiable financial or productivity benefits by Q4 2025, up from 16% a year prior. Software dev market projected to grow at 20% annually to $61B by 2029.",credibility:2},{id:"y26-str-3",phase:"Strategy",impactPct:15,year:2026,publishDate:"2026-01-15",source:"PwC — 2026 AI Business Predictions",sourceUrl:"https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html",dataType:"survey",description:"PwC 2026 AI Predictions: 60% of executives say Responsible AI boosts ROI and efficiency. AI tools reduce PM administrative work by 50-60%, freeing time for strategic work. However, many organizations still struggle to move beyond pilot phase.",credibility:2},{id:"y26-str-4",phase:"Strategy",impactPct:10,year:2026,publishDate:"2026-01-15",source:"Mind the Product — 2026 AI Product Strategy Guide",sourceUrl:"https://www.mindtheproduct.com/the-2026-ai-product-strategy-huide-how-to-plan-budget-and-build-without-buying-into-the-hype/",dataType:"anecdotal",description:"Mind the Product 2026 guide: AI tools for product managers reduce administrative work by 50-60%, freeing time for strategic decision-making. Warns against buying into hype — real gains come from disciplined adoption, not wholesale delegation.",credibility:1},{id:"y26-des-1",phase:"Design",impactPct:45,year:2026,publishDate:"2025-12-15",source:"Figma — AI Report 2025: Perspectives from Designers & Developers",sourceUrl:"https://www.figma.com/reports/ai-2025/",dataType:"survey",description:"Figma AI Report: 78% of professionals agree AI significantly enhances efficiency. 33% use AI to generate design assets; 22% use AI to create first drafts of interfaces. Designers who integrate AI into workflows ship features measurably faster.",sampleSize:"2,500 product builders across 7 countries",credibility:3},{id:"y26-des-2",phase:"Design",impactPct:50,year:2026,publishDate:"2026-01-15",source:"Index.dev — UI/UX Design Trends 2026",sourceUrl:"https://www.index.dev/blog/ui-ux-design-trends",dataType:"anecdotal",description:"Index.dev 2026 trends: designers who master AI tools ship features 40-60% faster. Wireframing tasks that took 3-4 hours now happen in minutes. AI design assistants handle layout generation, component suggestion, and style exploration.",credibility:1},{id:"y26-des-3",phase:"Design",impactPct:35,year:2026,publishDate:"2026-02-13",source:"Figma — State of the Designer 2026 (Extended)",sourceUrl:"https://www.figma.com/blog/state-of-the-designer-2026/",dataType:"survey",description:"Figma 2026 extended findings: 89% of designers say they are working faster; 80% report better collaboration with AI tools. However, only 32% say they can rely on AI output without significant manual refinement — indicating a quality ceiling.",sampleSize:"906 digital designers",credibility:3},{id:"y26-spec-1",phase:"Spec",impactPct:33,year:2026,publishDate:"2026-01-15",source:"ThoughtWorks — Spec-Driven Development with AI",sourceUrl:"https://thoughtworks.medium.com/spec-driven-development-d85995a81387",dataType:"vendor",description:"ThoughtWorks SDD: 30-35% productivity improvement with proper spec-driven development. Code review time decreased by 40%. Real-time notifications feature delivered in 2 days instead of 2 weeks (86% time reduction) when AI generates from well-defined specs.",credibility:2},{id:"y26-spec-2",phase:"Spec",impactPct:40,year:2026,publishDate:"2025-10-22",source:"Red Hat — Spec-Driven Development Improves AI Coding Quality",sourceUrl:"https://developers.redhat.com/articles/2025/10/22/how-spec-driven-development-improves-ai-coding-quality",dataType:"vendor",description:"Red Hat Developer: spec-driven development reduces time-to-productivity for new team members from weeks to days. Specifications contain complete system knowledge, enabling AI tools to generate more accurate implementations from well-structured requirements.",credibility:2},{id:"y26-spec-3",phase:"Spec",impactPct:25,year:2026,publishDate:"2026-01-15",source:"Built In — Spec-Driven Development as the Future of AI Engineering",sourceUrl:"https://builtin.com/articles/spec-driven-development-ai-assisted-software-engineering",dataType:"anecdotal",description:'Built In 2026: developer role shifts from "Code Writer" to "Technical Product Owner." AI code generation market projected from $4.91B (2024) to $30.1B by 2032. Well-structured specs become the primary productivity lever for AI-assisted development.',credibility:1},{id:"y26-spec-4",phase:"Spec",impactPct:30,year:2026,publishDate:"2026-01-15",source:"Anthropic — 2026 Agentic Coding Trends (Spec Impact)",sourceUrl:"https://resources.anthropic.com/2026-agentic-coding-trends-report",dataType:"vendor",description:"Anthropic agentic coding report: developers use AI in 60% of work but fully delegate only 0-20%. Organizations with clear specification practices see the highest gains — requirements clarity is the top predictor of AI coding agent success.",credibility:2},{id:"y26-dev-1",phase:"Dev",impactPct:-19,year:2026,publishDate:"2025-07-12",source:"METR — Randomized Controlled Trial on AI Developer Productivity",sourceUrl:"https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/",dataType:"empirical",description:"METR RCT (updated Feb 2026): AI use caused tasks to take 19% LONGER for experienced open-source developers (CI: +2% to +39%). Developers believed they were 20% faster — a stark perception-reality gap. Follow-up shows developer estimates shifting, suggesting learning effects.",sampleSize:"16 experienced developers, 246 issues",credibility:3},{id:"y26-dev-2",phase:"Dev",impactPct:53,year:2026,publishDate:"2026-01-15",source:"Opsera — 2026 AI Coding Impact Benchmark (Dev Productivity)",sourceUrl:"https://opsera.ai/resources/report/ai-coding-impact-2025-benchmark-report/",dataType:"empirical",description:"Opsera 2026 benchmark: 48-58% faster Time-to-PR with AI tools. Senior engineers see 5x the productivity gains of juniors. However, code duplication rises from 10.5% to 13.5% and AI-generated PRs wait 4.6x longer for review.",sampleSize:"250,000+ developers across 60+ enterprise organizations",credibility:3},{id:"y26-dev-3",phase:"Dev",impactPct:21,year:2026,publishDate:"2026-01-15",source:"Faros AI — The AI Productivity Paradox Report",sourceUrl:"https://www.faros.ai/blog/ai-software-engineering",dataType:"empirical",description:"Faros AI Paradox: developers with high AI adoption complete 21% more tasks and merge 98% more PRs. BUT PR review time increases 91%, AI-generated PRs have 1.7x more issues (10.83 vs 6.45), and 9% increase in bugs per developer. No significant correlation with better DORA metrics.",sampleSize:"10,000+ developers across 1,255 teams",credibility:3},{id:"y26-dev-4",phase:"Dev",impactPct:42,year:2026,publishDate:"2026-01-15",source:"SonarSource — 2026 State of Code Developer Survey",sourceUrl:"https://www.sonarsource.com/blog/state-of-code-developer-survey-report-the-current-reality-of-ai-coding/",dataType:"survey",description:"SonarSource 2026: AI accounts for 42% of all committed code (expected to rise to 65% by 2027). 96% of developers don't fully trust AI output; only 48% always verify. Teams spend 24% of their week checking/fixing AI output. 72% of AI users use it daily.",sampleSize:"1,100+ professional developers",credibility:3},{id:"y26-dev-5",phase:"Dev",impactPct:79,year:2026,publishDate:"2026-01-15",source:"Anthropic — 2026 Agentic Coding Trends Report",sourceUrl:"https://resources.anthropic.com/2026-agentic-coding-trends-report",dataType:"vendor",description:"Anthropic 2026 report: Rakuten reduced time-to-market by 79% (24 days to 5 days) using Claude. TELUS shipped code 30% faster with 500,000 hours saved across 57,000+ team members. Organizations report 30-79% faster development cycles with agentic AI.",credibility:2},{id:"y26-dev-6",phase:"Dev",impactPct:200,year:2026,publishDate:"2025-05-20",source:"Anthropic — How AI is Transforming Work (Internal Report)",sourceUrl:"https://www.anthropic.com/research/how-ai-is-transforming-work-at-anthropic",dataType:"vendor",description:"Anthropic internal report: engineering productivity increased 200% per engineer with Claude Code. 70% fewer production bugs, 50% faster debugging, 90% test coverage vs 40% without. 60-70% time reduction for large codebase modifications.",credibility:2},{id:"y26-dev-7",phase:"Dev",impactPct:25,year:2026,publishDate:"2026-01-15",source:"McKinsey — Unlocking the Value of AI in Software Development",sourceUrl:"https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/unlocking-the-value-of-ai-in-software-development",dataType:"survey",description:"McKinsey 2026: top performers see 16-30% team productivity improvement; 31-45% improvement in software quality. Organizations with 80-100% adoption see >110% gains. 60%+ of 600 orgs surveyed see at least 25% productivity improvement.",sampleSize:"600+ organizations",credibility:3},{id:"y26-dev-8",phase:"Dev",impactPct:-17,year:2026,publishDate:"2026-02-05",source:"Anthropic — AI and Skill Formation Study",sourceUrl:"https://www.infoq.com/news/2026/02/ai-coding-skill-formation/",dataType:"empirical",description:"Anthropic study (Feb 2026): developers using AI assistance scored 17% lower on comprehension tests. Those using AI for conceptual inquiry scored 65%+; those delegating code generation to AI scored below 40%. AI as teacher works; AI as crutch degrades skills.",credibility:3},{id:"y26-dev-9",phase:"Dev",impactPct:55,year:2026,publishDate:"2026-01-15",source:"GitHub — Copilot Productivity Statistics 2026",sourceUrl:"https://www.getpanto.ai/blog/github-copilot-statistics",dataType:"vendor",description:"GitHub Copilot 2026 statistics: developers code up to 55% faster. Copilot generates 46% of code on average (61% for Java). 20M+ cumulative users, adopted by 90% of Fortune 100. Code readability +3.62%, reliability +2.94%, maintainability +2.47%.",sampleSize:"4,800 developers surveyed",credibility:2},{id:"y26-dev-10",phase:"Dev",impactPct:38,year:2026,publishDate:"2026-02-15",source:"Google — Antigravity Agentic Development Platform",sourceUrl:"https://developers.googleblog.com/build-with-google-antigravity-our-new-agentic-development-platform/",dataType:"vendor",description:"Google Antigravity IDE (Gemini 3 Pro powered): 76.2% on SWE-bench Verified. 38% speed advantage over competitor IDEs (42s vs 68s for standard feature). 94% refactoring accuracy vs 78% for competitors. Supports up to 8 parallel agents simultaneously.",credibility:2},{id:"y26-qa-1",phase:"QA",impactPct:60,year:2026,publishDate:"2026-01-15",source:"Tricentis — QA Trends 2026: AI Agentic Testing",sourceUrl:"https://www.tricentis.com/blog/qa-trends-ai-agentic-testing",dataType:"vendor",description:"Tricentis 2026: customer achieved 85% reduction in manual effort and 60% increase in productivity using AI testing agents. AI-driven test generation and execution dramatically cuts manual test case creation effort.",credibility:2},{id:"y26-qa-2",phase:"QA",impactPct:35,year:2026,publishDate:"2026-01-15",source:"TestGrid — Software Testing Statistics 2026",sourceUrl:"https://testgrid.io/blog/software-testing-statistics/",dataType:"survey",description:"TestGrid 2026: QA market valued at $57.73B. 60%+ of QA pipelines are automation-driven. 10% of respondents have used GenAI to generate up to 75% of all test scripts. AI-powered testing adoption accelerating but uneven across organizations.",credibility:2},{id:"y26-qa-3",phase:"QA",impactPct:40,year:2026,publishDate:"2026-01-15",source:"ThinksYS — QA Trends Report 2026",sourceUrl:"https://thinksys.com/qa-testing/qa-trends-report-2026/",dataType:"survey",description:'ThinksYS 2026: 72.8% of respondents selected "AI-powered testing & autonomous test generation" as top priority. Automation testing market projected to reach $55.2B by 2028. AI agents increasingly handle regression testing and exploratory testing tasks.',credibility:2},{id:"y26-qa-4",phase:"QA",impactPct:-40,year:2026,publishDate:"2026-01-15",source:"SonarSource — The Verification Gap in AI Coding",sourceUrl:"https://www.sonarsource.com/company/press-releases/sonar-data-reveals-critical-verification-gap-in-ai-coding/",dataType:"survey",description:"SonarSource verification gap: 96% of developers don't fully trust AI output; only 48% always verify before committing. 88% cite negative impacts of AI (unreliable code that looks correct). Estimated 40% quality deficit projected — AI boosts output but degrades quality assurance.",sampleSize:"1,100+ developers",credibility:3},{id:"y26-qa-5",phase:"QA",impactPct:30,year:2026,publishDate:"2026-01-15",source:"Faros AI — AI Productivity Paradox (QA Impact)",sourceUrl:"https://www.faros.ai/blog/ai-software-engineering",dataType:"empirical",description:"Faros AI QA findings: AI-generated PRs have 1.7x more issues (10.83 vs 6.45 per PR). PR review time increases 91% for AI-assisted code. While AI helps generate tests faster, the net QA burden increases due to higher defect rates in AI-generated code.",sampleSize:"10,000+ developers across 1,255 teams",credibility:3},{id:"y26-ops-1",phase:"DevOps",impactPct:45,year:2026,publishDate:"2026-02-15",source:"Perforce — 2026 State of DevOps Report (Extended)",sourceUrl:"https://www.perforce.com/resources/state-of-devops",dataType:"survey",description:"Perforce 2026: 72% of high-maturity orgs have AI embedded across SDLC. 87% believe AI will enable engineers to focus on system design vs scripting. 77% have confidence in AI outputs. 55% of QA teams shifted focus to quality analytics.",sampleSize:"820 technology professionals worldwide",credibility:3},{id:"y26-ops-2",phase:"DevOps",impactPct:30,year:2026,publishDate:"2026-01-15",source:"Softjourn — AI Transforming DevOps 2026",sourceUrl:"https://softjourn.com/insights/how-ai-is-transforming-devops",dataType:"survey",description:"Softjourn 2026: 30% reduction in deployment failures; 20% improvement in deployment speed; 50% reduction in unplanned downtime for mature AI-DevOps organizations. 67% of DevOps teams increased AI investment in the past year.",credibility:2},{id:"y26-ops-3",phase:"DevOps",impactPct:35,year:2026,publishDate:"2025-08-26",source:"Gartner — Enterprise AI Agents Prediction 2026",sourceUrl:"https://www.gartner.com/en/newsroom/press-releases/2025-08-26-gartner-predicts-40-percent-of-enterprise-apps-will-feature-task-specific-ai-agents-by-2026-up-from-less-than-5-percent-in-2025",dataType:"vendor",description:"Gartner predicts 40% of enterprise apps will have task-specific AI agents by end of 2026, up from <5% in 2025. Agentic AI could drive ~30% of enterprise app software revenue ($450B+) by 2035. But warns 40%+ of agentic AI projects will be cancelled by 2027.",credibility:2},{id:"sci-dev-1",phase:"Dev",impactPct:26,year:2025,publishDate:"2025-06-15",source:"MIT/Microsoft/Accenture — Three Field Experiments with Software Developers",sourceUrl:"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4945566",dataType:"empirical",description:"Three field RCTs across Microsoft, Accenture, and a Fortune 100 company: 26.08% increase in completed tasks for Copilot group. Junior developers: +21-40%; senior developers: +7-16%. The largest controlled study of AI coding productivity to date.",sampleSize:"4,867 developers across 3 companies",credibility:3},{id:"sci-dev-2",phase:"Dev",impactPct:56,year:2025,publishDate:"2023-02-14",source:"Peng et al. — Impact of AI on Developer Productivity (arXiv:2302.06590)",sourceUrl:"https://arxiv.org/abs/2302.06590",dataType:"empirical",description:"RCT: treatment group completed HTTP server task 55.8% faster (95% CI: 21-89%). Less experienced developers benefited most. One of the earliest rigorous controlled experiments on GitHub Copilot productivity.",sampleSize:"95 professional developers",credibility:3},{id:"sci-dev-3",phase:"Dev",impactPct:30,year:2026,publishDate:"2025-11-07",source:"He, Miller et al. (CMU) — Speed at the Cost of Quality (arXiv:2511.04427)",sourceUrl:"https://arxiv.org/abs/2511.04427",dataType:"empirical",description:"CMU causal study (MSR '26): Cursor AI causes 3-5x increase in lines added in first adoption month (transient). But static analysis warnings +30% and code complexity +41% (persistent). Velocity gains dissipate after 2 months — the quality tradeoff is real.",credibility:3},{id:"sci-dev-4",phase:"Dev",impactPct:25,year:2026,publishDate:"2026-01-23",source:"AI IDEs vs Autonomous Agents — Measuring Impact of Coding Agents (arXiv:2601.13597)",sourceUrl:"https://arxiv.org/abs/2601.13597",dataType:"empirical",description:"Staggered difference-in-differences study: agent-first projects see large front-loaded velocity gains. But static analysis warnings +18% and cognitive complexity +39% persistently. Repos with prior AI IDE usage see minimal additional gains from agents.",credibility:3},{id:"sci-dev-5",phase:"Dev",impactPct:32,year:2025,publishDate:"2025-09-29",source:"Kumar et al. — Intuition to Evidence: AI's True Impact on Developer Productivity (arXiv:2509.19708)",sourceUrl:"https://arxiv.org/abs/2509.19708",dataType:"empirical",description:"Enterprise longitudinal study: 31.8% reduction in PR review cycle time. Top adopters: 61% increase in code volume pushed to production. AI contributed 28-40% of code shipped. Adoption scaled from 4% to 83% peak over 6 months.",sampleSize:"300 engineers, 1-year study",credibility:2},{id:"sci-dev-6",phase:"Dev",impactPct:4,year:2025,publishDate:"2026-01-15",source:"Daniotti, Wachs et al. — Global Diffusion of AI Coding (Science)",sourceUrl:"https://arxiv.org/abs/2506.08945",dataType:"empirical",description:"Published in Science: AI writes 29% of Python functions in the US. Quarterly output increased by 3.6% due to AI — modest at the macro level. Experienced programmers capture nearly all productivity gains, widening the skill gap rather than closing it.",sampleSize:"30 million GitHub commits, 170,000 developers",credibility:3},{id:"sci-dev-7",phase:"Dev",impactPct:54,year:2026,publishDate:"2026-01-30",source:"Agentic Coding Adoption on GitHub (arXiv:2601.18341)",sourceUrl:"https://arxiv.org/abs/2601.18341",dataType:"empirical",description:"Large-scale mining study: agent adoption rate 15.85-22.60% of GitHub projects. Among Claude Code agent-assisted PRs (567 PRs across 157 projects): 83.8% merged, 54.9% merged without any human modification.",sampleSize:"129,134 GitHub projects",credibility:2},{id:"sci-dev-8",phase:"Dev",impactPct:29,year:2026,publishDate:"2026-01-31",source:"AGENTS.md Impact on AI Coding Agent Efficiency (arXiv:2601.20404)",sourceUrl:"https://arxiv.org/abs/2601.20404",dataType:"empirical",description:"AGENTS.md context files associated with 29% reduction in median agent runtime and 17% reduction in output token consumption. Only ~5% of surveyed repos have adopted context files — a low-hanging-fruit optimization for AI-assisted development.",sampleSize:"466 repositories",credibility:2},{id:"sci-dev-9",phase:"Dev",impactPct:10,year:2026,publishDate:"2026-02-05",source:"BNY Mellon — Beyond the Commit: Developer Perspectives on AI Productivity (arXiv:2602.03593)",sourceUrl:"https://arxiv.org/abs/2602.03593",dataType:"survey",description:"ICSE-SEIP '26: developer satisfaction does not directly equate to time savings. Six distinct factors capture productivity dimensions. Commit frequency and code acceptance rates are inadequate proxies for true productivity. Self-reported gains do not match measured ones.",sampleSize:"2,989 developer responses, 11 in-depth interviews",credibility:3},{id:"sci-dev-10",phase:"Dev",impactPct:81,year:2026,publishDate:"2026-02-24",source:"Anthropic — Claude Opus 4.5 SWE-bench Verified (Feb 2026)",sourceUrl:"https://www.vellum.ai/blog/claude-opus-4-6-benchmarks",dataType:"vendor",description:"SWE-bench Verified leaderboard (Feb 2026): Claude Opus 4.5 scores 80.9%, Claude Opus 4.6 scores 80.8%, Gemini 3.1 Pro scores 80.6%, Gemini 3 Pro scores 76.2%. Models now resolve 4 out of 5 real-world GitHub issues autonomously.",sampleSize:"500 SWE-bench tasks",credibility:2},{id:"sci-qa-1",phase:"QA",impactPct:-41,year:2026,publishDate:"2025-11-07",source:"He, Miller et al. (CMU) — Speed at the Cost of Quality: QA Impact (arXiv:2511.04427)",sourceUrl:"https://arxiv.org/abs/2511.04427",dataType:"empirical",description:"CMU causal study (MSR '26): AI coding tool adoption leads to persistent +41% increase in code complexity and +30% more static analysis warnings. Quality degradation does not diminish over time — teams need proportionally more QA effort to compensate.",credibility:3},{id:"sci-qa-2",phase:"QA",impactPct:25,year:2025,publishDate:"2024-09-01",source:"Garousi et al. — AI-Powered Software Testing Tools: Systematic Review (arXiv:2409.00411)",sourceUrl:"https://arxiv.org/abs/2409.00411",dataType:"empirical",description:"Systematic review of 55 AI testing tools: AI enhances test execution efficiency and reduces maintenance effort. But exposes limitations in handling complex UI changes and contextual understanding. Best results in regression and API testing.",sampleSize:"55 AI testing tools evaluated",credibility:2},{id:"sci-qa-3",phase:"QA",impactPct:35,year:2025,publishDate:"2025-12-06",source:"WhatsCode (Meta/WhatsApp) — GenAI for Code Quality (arXiv:2512.05314)",sourceUrl:"https://arxiv.org/abs/2512.05314",dataType:"empirical",description:"ICSE-SEIP '26: WhatsApp deployed GenAI for 25 months. Privacy verification coverage improved 3.5x (15% to 53%). 86% precision in automated bug triage. 692 automated refactor/fix changes accepted. Demonstrates enterprise-scale AI QA deployment.",credibility:2},{id:"sci-ops-1",phase:"DevOps",impactPct:20,year:2026,publishDate:"2026-01-27",source:"Where Do AI Coding Agents Fail? Failed PRs on GitHub (arXiv:2601.15195)",sourceUrl:"https://arxiv.org/abs/2601.15195",dataType:"empirical",description:"Mining study of 33,000 agent-authored PRs by 5 coding agents. Documentation and CI/build PRs achieve highest merge success. Performance optimization and bug-fix tasks perform worst. Failed PRs tend to involve larger changes and touch more files.",sampleSize:"33,000 agent-authored pull requests",credibility:2},{id:"sci-ops-2",phase:"DevOps",impactPct:35,year:2025,publishDate:"2025-12-06",source:"WhatsCode (Meta/WhatsApp) — GenAI for DevOps (arXiv:2512.05314)",sourceUrl:"https://arxiv.org/abs/2512.05314",dataType:"empirical",description:"ICSE-SEIP '26: WhatsApp's WhatsCode platform processed 3,000+ accepted code changes and 711 automated framework adoption migrations over 25 months. GenAI agents handle CI/CD pipeline configuration and dependency management at enterprise scale.",credibility:2},{id:"metr-th-1",phase:"Dev",impactPct:55,year:2026,publishDate:"2026-02-20",source:"METR — AI Task-Completion Time Horizons",sourceUrl:"https://metr.org/time-horizons/",dataType:"empirical",description:"METR benchmark (v1.1, Feb 2026): AI capability in software engineering tasks doubles every ~4 months (123 days, CI: 100–149) based on 2023-onward data. Claude Opus 4.6 achieves 870-hour 50%-time horizon — able to autonomously complete tasks that take human experts weeks.",sampleSize:"100+ diverse software engineering tasks",credibility:3},{id:"metr-th-2",phase:"Dev",impactPct:45,year:2026,publishDate:"2026-02-20",source:"METR — AI Task-Completion Time Horizons",sourceUrl:"https://metr.org/time-horizons/",dataType:"empirical",description:"METR benchmark: All-time AI capability doubling rate is ~7 months (196 days, CI: 162–223). From GPT-2 (0.04h time horizon) to Claude Opus 4.6 (870h), representing a >20,000x improvement in autonomous task completion scope across software engineering, ML, and cybersecurity.",sampleSize:"RE-Bench, HCAST, novel software tasks",credibility:3},{id:"metr-th-3",phase:"QA",impactPct:50,year:2026,publishDate:"2026-02-20",source:"METR — AI Task-Completion Time Horizons",sourceUrl:"https://metr.org/time-horizons/",dataType:"empirical",description:"METR time horizon analysis: Frontier AI agents can now reliably complete multi-day cybersecurity and testing tasks autonomously. The exponential capability trend (doubling every 4 months recently) implies tasks requiring 1,700+ hours of human expert time may be within AI reach within a year.",sampleSize:"100+ diverse tasks across SE, ML, cybersecurity",credibility:3}]])}]);